{
  
    
        "post0": {
            "title": "Diving into BoardGameGeek",
            "content": ". Do you like board games? If you do, you may wonder what other great games are out there. I admit that it&#39;s a bit of a guilty pleasure of mine. Many people turn to BoardGameGeek (BGG). This is a great site with many users rating games. I used the BGG API to gather information about: . 410K users rating 19M games | Information on 22K games, such as game type, complexity, minimum age, game duration etc | . The key insights from this dataset are: . New games receive higher ratings | More complex games receive higher ratings | Less active users give higher ratings | . In this post we take a deeper look into these insights and explore alternative ways of ranking the best games. . Let&#39;s dive in! . The users and ratings . Users give ratings that are often rounded: they give a 7 instead of a 7.23, that&#39;s why you see the spikes on the leftmost chart. Around 4 million reviews end up with a 7. . Looking at the games, we see a nice normal distribution. . 19% of users only leave 1 rating. Together they only account for 0.5% of all ratings | 5% of users (20k) rating &gt;200 games. Together they account for 27% of all ratings | 44% of games receive &lt;100 ratings. However, these ratings only account of 6% of all ratings. | 7% of games have &gt;2000 ratings. Together they account for 39% of all ratings. | . Most active users &nbsp; user count average . 1 oldgoat3769967 | 6471 | 6.185752 | . 2 warta | 6289 | 7.230800 | . 3 leffe dubbel | 6068 | 5.937541 | . 4 TomVasel | 5672 | 6.401869 | . 5 Doel | 5131 | 7.496200 | . Most reviewed games &nbsp; Name count average . 1 Pandemic | 108971 | 7.594996 | . 2 Carcassonne | 108881 | 7.416162 | . 3 Catan | 108195 | 7.133179 | . 4 7 Wonders | 90110 | 7.733539 | . 5 Dominion | 81623 | 7.607675 | . Check out the insane number of ratings by oldgoat. And 3 games so close to each other with &gt;100K ratings! . Developments over the years . There has been incredible growth in the amount of boardgames being released. It does appears to slow down, although many games are for some mysterious reason added a couple of years after they have been released. Therefore the steep drop after 2020 is a bit misleading. . Are games being rated higher? After 2005 it seems so! Are games nowadays just better or is there a tendency to rate new games higher? Now luckily I&#39;ve composed this dataset already twice in the past, we can make good use of this: . My conclusion would be that it&#39;s a mix of improved quality and hype: . Scores have been climbing since 2005. There is a rough consensus that boardgames have improved in quality. | As you see the 3 snapshots diverge around 2015. This is a &#39;hype&#39; effect, where the early adopters score a new/upcoming games higher. For any year, the blue line (the ratings from the dataset in 2019) scores highest, after the orange (2020) and lowest in the most recent version of the dataset (2022). Games from 2020 where rated with 7.8 in 2020, but two years later that has dropped to 7.2 and now games from 2022 are rated with 7.8! When games are about 5 years old the &#39;hype&#39; effect is more or less gone and games reach a stable score (around 2014 there is no difference anymore). | . Edit: some BGG users are pointing out it may also have to do with users getting more selective in which games they play . Complexity of games . BGG has a weight metric, which means how complex a game is. To get a feel what a number means, here some examples: . Monopoly: 1.3 | Catan: 2.3 | Chess: 3.7 | . Most of the games have a fairly low weight. . There is a relation between the complexity of the game and the score. More complex games get higher scores, it&#39;s almost a 1 point difference between a game with weight 1 and 5! Are heavy games really &#39;better&#39; than &#39;light&#39; games? . Are active users more critical? . Here you see the average rating that different user groups are giving. I&#39;ve split the population in 3 parts that all account for 33% of the ratings. The very active group gives lower scores (6.9 avg) compared to the active users (7.2 avg) and the normal users (8.1 avg). The very active users only make up of 6% the population (note it&#39;s a small area), they do give out 33% of the ratings! . Are normal users less critical or just reviewing better quality games? . It&#39;s notable that 11% of all users give a 10 on average, which accounts for 0.5% of all ratings. You can make a case for filtering these ratings out. Some of the games are rated by many users that have only rated one game with a 10. A good example of such a game is Goblin Grapple, but there are around 100 games that I find suspect. . What is the best game? . While doing this project so many ideas came to mind on how an alternative ranking could be defined: . Excluding ratings given by inactive users (I took &lt;=10 as threshold) | Excluding games that have received &#39;few&#39; ratings (I took &lt;= 1000) | Accounting for the complexity bonus, so that lighter games end up higher. | . Other ideas: . Account for the release year. This approach I abandoned, since some new games are truly better. The only thing you want to account for is removing the &#39;hype&#39; effect. I did this by excluding games after 2017 from the analysis. | Including ratings with a comment, since these people are more strongly opinionated. It did not differ much. | Training a model that takes the average user rating into account, to account for people consistently rating high or low. | . Let me show you some of the outcomes . name avg_rating yearpublished averageweight . 1 Gloomhaven | 8.64 | 2017 | 3.87 | . 2 Twilight Imperium: Fourth Edition | 8.59 | 2017 | 4.26 | . 3 Pandemic Legacy: Season 1 | 8.56 | 2015 | 2.83 | . 4 War of the Ring: Second Edition | 8.45 | 2012 | 4.17 | . 5 Gaia Project | 8.43 | 2017 | 4.37 | . 6 Star Wars: Rebellion | 8.38 | 2016 | 3.73 | . 7 Terraforming Mars | 8.36 | 2016 | 3.24 | . 8 Too Many Bones | 8.36 | 2017 | 3.84 | . 9 Through the Ages: A New Story of Civilization | 8.35 | 2015 | 4.41 | . 10 Aeon&#39;s End: War Eternal | 8.34 | 2017 | 2.93 | . This corresponds more or less to the top games listed on BGG. Note from &#39;averageweight&#39; that these are all pretty heavy games. Also 2017 appears 5 times. . But I don&#39;t have time to play games that are very complex and take many hours! So let&#39;s account for the complexity, such that great lighter games will pop up more. I trained a tree based model with a r2 of 0.3. It&#39;s only 0.3, but that does mean that 30% of the variation in the rating is explained by the complexity! . Best games with complexity taken into account . I trained a model that tries to predict the rating of a game based on it&#39;s complexity. What the model cannot explain by complexity (so-called residuals) is more or less the quality of the game without the complexity bias. I&#39;ve taken 1000 reviews as a minimum for the game to be included. That is pretty harsh (only leaves ~15% of the games), but I wanted to be able to recognize some games. This results in the following top 10: . name residual average yearpublished averageweight . 1 Crokinole | 1.75 | 7.95 | 1876 | 1.25 | . 2 Monikers | 1.61 | 7.80 | 2015 | 1.06 | . 3 Telestrations: 12 Player Party Pack | 1.56 | 7.75 | 2011 | 1.07 | . 4 Time&#39;s Up! Title Recall! | 1.51 | 7.71 | 2008 | 1.19 | . 5 KLASK | 1.45 | 7.64 | 2014 | 1.08 | . 6 Pandemic Legacy: Season 1 | 1.42 | 8.59 | 2015 | 2.83 | . 7 Escape the Dark Castle | 1.32 | 7.51 | 2017 | 1.23 | . 8 Time&#39;s Up! Edici√≥n Amarilla | 1.30 | 7.49 | 2008 | 1.11 | . 9 Eat Poop You Cat | 1.26 | 7.45 | 0 | 1.11 | . 10 Mythic Battles: Pantheon | 1.26 | 8.43 | 2017 | 3.03 | . This list is ordered by residual, the part that the model could not explain. There are a lot of dexterity and party games in the top, which are of course light games. Pandemic Legacy scores high even while being fairly complex. I was a bit shaken by Eat Poop You Cat, but it seems a nice game you can play with pen and paper. If we filter out the easiest games we get the following list: . name residual average yearpublished averageweight . 1 Pandemic Legacy: Season 1 | 1.42 | 8.59 | 2015 | 2.83 | . 2 Mythic Battles: Pantheon | 1.26 | 8.43 | 2017 | 3.03 | . 3 Gloomhaven | 1.24 | 8.74 | 2017 | 3.87 | . 4 Star Realms: Colony Wars | 1.22 | 7.85 | 2015 | 1.90 | . 5 Azul | 1.21 | 7.80 | 2017 | 1.76 | . 6 Aeon&#39;s End: War Eternal | 1.21 | 8.38 | 2017 | 2.93 | . 7 7 Wonders Duel | 1.19 | 8.11 | 2015 | 2.22 | . 8 Twilight Imperium: Fourth Edition | 1.18 | 8.68 | 2017 | 4.26 | . 9 Patchwork | 1.14 | 7.64 | 2014 | 1.62 | . 10 Kingdom Death: Monster | 1.11 | 8.61 | 2015 | 4.26 | . We do see some heavy games popping back, but there are lighter games as well. I know Pandemic, Azul, 7 Wonders Duel and Patchwork to be great games! . Wrapping things up with a complete model . Finally I&#39;ve also trained a model on multiple variables, e.g. the type of game and the year of publication. This model is able to account for about 50% of the variation between average game scores. I think this is a pretty good result. Below you see the impact of the most important variables. . As expected the weight/complexity and year of publication have most impact on the rating of a game. Together they roughly impact the score by 0.5 for each game. In addition certain categories also have a small impact on the score. In more detail: . This is what people talk about with &#39;explainable AI&#39;. All the dots represent games, and if they are on the right side it means the impact on the model was positive (a higher rating). The color is about the feature value, where blue means low and red high. . What works best is saying it out loud: &#39;if averageweight is high (red), then the impact is positive and the game will receive higher ratings. For &#39;AdminBetterDescriptionNeeded&#39; that means that if the game description is lacking, the game will receive lower ratings. . So if you want to receive high ratings with your game, just make sure to make it complex, two players simulated wargame that can be played solitaire with miniatures and online as well. You already get the hype effect for free üòã . We can also inspect how to model came to it&#39;s prediction for a single game. Below I took Chess as an example: . The average game receives a 6.8 (see the bottom value), then there are all kind of effects going on, with the red bars pushing the prediction higher, the blue ones lower. Chess is quite complex which pushes the prediction up, but it&#39;s also old. Apparently the model also doesn&#39;t like you need to be 6 to play it. All these effects together make the model arrive at a prediction of 7.1. . Summarizing, we have found that there are multiple features that influence the rating of a game. Also we have explored alternatives of ranking the best games. Finally we put everything together with an explainable machine learning model. Hope you enjoyed this dive into the data behind board games! . . Tip: Some technical info: I&#8217;ve used standard Python data science packages such as Pandas and Matplotlib, SQLite for database, trained models with LightGBM and the interpretation with SHAP. For the blogging in a notebook I use Fastpages. All awesome! . . Note: The data is of course owned by BoardGameGeek. If you want to play with the data, I&#8217;ve made it into a Kaggle Dataset .",
            "url": "https://jvanelteren.github.io/blog/2022/01/19/boardgames.html",
            "relUrl": "/2022/01/19/boardgames.html",
            "date": " ‚Ä¢ Jan 19, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Playing around with GLIDE image model",
            "content": "You probably know that a computer can describe an image. For example an image of a dog playing with your kids may be translated into &#39;dog and children in garden&#39;. . But did you know the other way around is now also possible? You come up with a text and the computer renders a new image. Completely new, not like a Google search which searches existing images. . OpenAI has been one of the premier organisations publishing spectacular results in the past years. They train their models on huge datasets of texts and images. They released a paper on their GLIDE image model, trained on several hundred million images. It outperforms their previous &#39;DALL-E&#39; model in terms of photorealism. . They also open-sourced a slimmed down version of their model. I played around with it by coming up with text prompts and let the model generate 10 images for each promt. . Below the results. Zoom in on pc with ctrl+mousewheel or on mobile with your fingers. I repeat the text above the images keep it readable while zoomed in. . . What do you think? Some things I noticed: . The more complex prompts sometimes are only partially fulfilled. For example: a monkey looking at itself in the mirror often does not render the mirror. | The representation sometimes is off, for example the secondright rubber ducky. | The model can be quite wide in it&#39;s approach. When you think of a &#39;map of a city&#39;, you probably have 1 type of map in your head. The model generates all sorts of types of maps, all believable | . I also had a culinary adventure: Tried out &#39;spagetthi on a plate&#39; but got results that didn&#39;t look like somethink I&#39;d like to consume... Turned out I misspelled it (should be spaghetti) and the corrected text looked much better. To finish it off, I tried to make it &quot;delicious&quot; and worked out pretty nicely, often the spaghetti get&#39;s some vegetables on top. So next time you order spaghetti in a restaurant, make sure to spell it right! . . The full GLIDE model is larger and also is trained on images of people. See these impressive examples from the paper: . . This clearly is a disruption to the stock photo business and does have a wide variety of use cases. . At this point AI can generate believeable news articles including images that are completely false. Still though, many experts feel that we are currently a long way from Artifical General Intelligence and the current deep learning architectures may not get us to AGI. . To me, that doesn&#39;t make these &#39;narrow&#39; intelligence less impressive. Hope you enjoyed it! . . Tip: There are even more examples in the paper, check it out! And in case you can&#8217;t get enough, I&#8217;ve got even more examples .",
            "url": "https://jvanelteren.github.io/blog/2022/01/03/glide_image_model.html",
            "relUrl": "/2022/01/03/glide_image_model.html",
            "date": " ‚Ä¢ Jan 3, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Advent of Code analysis through the years",
            "content": ". Since 2018 I&#39;m participating in üéÖAdvent of CodeüéÖ and enjoying it a great deal. Since AoC has been running since 2015 there has been a sizable amount of data generated. Let&#39;s see what we can learn, starting with the amount of stars awarded each season. . . In total there have now been more than 10M stars awarded! After a &#39;rough&#39; 2016, AoC has been steadily growing with 2020 as a (Covid?) 100% boost. . Edit: as BBQspaceflight indicated on the AoC Reddit, probably 2016 was not a rough year, but many people have been solving 2015 at a later time (e.g. they participated in 2018 and afterwards did 2015). . This plot was originally from Maurits vd Schee. I only plotted the full day. It&#39;s a familiar sight: in general the times are below the hour mark, with a couple going higher. In 2020 and 2021 the completion times look more compressed. . Low completion times can be a result of two factors: . The puzzles were easier | The participants where better / more competitive | . One way of investigating the difficulty of a year is by analyzing the completion rate: how many people got all the stars compared to the people that got only 1 star of day 25. These people did make it to day 25, thus put a considerable amount of effort in, but couldn&#39;t finish all puzzles. . I didn&#39;t wanted to take all participants from day 1, since that number quickly drops during the first couple of days. . In the above chart, each rectangle symbolizes the people that solved all puzzles during the year. The height shows the completion rate. . The completion rate was very high in 2016 and 2017 and lowest in 2018. In 2020 many people finished all puzzles, corresponding with more participants that year. . For 2021 the verdict is still out, in a couple of months people will have had time to finish so the completion rate will stabilize. . . We see that: . The amount of finishers (people getting all stars) peaked in 2020 | The amount of people that got points on the leaderboard is slowly increasing with 2015 also being very high. Why? | The percentage of finishers getting points is varying. Lower percentages could indicate how competitive the year was. | . Another indicator can be the time it took to solve a puzzle. . The fastest completion times add up to around 3 hours, which is amazing. Since nobody ever finished #1 at all puzzles, this is a theoretical minimum. . The completion times of #100 add up to a more &#39;human&#39; amount. These times are still way below the amount of time a &#39;normal&#39; participant spends on AoC. For example I consider myself an enthusiast, but my completion times are normally about 2-3x the #100. . There does seem to be some correlation between the total time the #100 took and the amount of participants finishing all puzzles. Although I&#39;m not sure if it&#39;s causal, could be there are other variables playing a role. . . Getting leaderboard points is quite special (I never made it, highscore 119th once), but there are people who do it consistently. Let&#39;s give the top 30 some extra recognitionüéà . All the people on this top 30 list are amazing, but some awards to hand out: . üèÜRobert Xiao managed to get the most amount of points and overall most leaderboard placements | üèÜbetaveros got on average most points &amp; leaderboard entries (ignoring anonymous user here). betaveros also managed to get 50 entries is 2018, which was a one-time event | üèÜglguy for getting the highest score while getting points in all 7 seasons | . . Doing AoC once and get LB points is nice, but it&#39;s even nicer to do it twice, thrice, etc. . Most of the people that get points manage to do it only once. The y-axis is logaritmic. Who are having so much grit to get points all 7 seasons? . user amount_seasons total_points total_leaderboard_placements . 9 glguy | 7 | 10948 | 172 | . 12 etotheipi1 | 7 | 9978 | 179 | . 18 msullivan | 7 | 8561 | 147 | . 19 Kevin Yap | 7 | 8282 | 145 | . 43 (anonymous user #60233) | 7 | 5663 | 111 | . 69 Daniel Rejment | 7 | 3783 | 78 | . 81 Roderic Day | 7 | 3578 | 72 | . 111 lukechampine | 7 | 3013 | 71 | . 241 Shane Mc Cormack | 7 | 1658 | 29 | . glguy topping the list. Coming back to our competitiveness discussion, how many points did they score together? . It&#39;s varying but 2020 and 2021 are lower. This could reflect: . increased competitiveness during the years | natural variation | legends getting olderüòä | . All in all an amazing achievement! All in all I think there is a strong case for 2020 and 2021 being more competitive. . Let&#39;s finally turn to which puzzles were easiest or hardest. . . puzzle user time (seconds) . 0 2019-1-1 | bluepichu | 23 | . 1 2018-1-1 | Tris Emmy Wilson | 26 | . 2 2021-1-1 | betaveros | 28 | . 3 2020-1-1 | Anish Singhani | 35 | . 4 2017-2-1 | xiaowuc1 | 36 | . The easiest puzzles are mostly on day 1. In 2019, the first star was obtained after just 23 seconds! . puzzle lb full (seconds) . 0 2021-1-1 | 65 | . 1 2019-1-1 | 84 | . 2 2018-1-1 | 92 | . 3 2021-2-1 | 98 | . 4 2021-7-1 | 112 | . The leaderboard capped (the #100 completed the puzzle) after barely a minute in 2021 for the first star! . . puzzle user time (minutes) title . 349 2018-15-2 | Simon Parent | 36 | Beverage Bandits | . 348 2018-17-2 | Raven Black | 33 | Reservoir Research | . 345 2018-24-2 | Simon Parent | 28 | Immune System Simulator 20XX | . 344 2020-20-2 | xiaowuc1 | 25 | Jurassic Jigsaw | . 342 2021-23-2 | goffrie | 23 | Amphipod | . 341 2019-18-2 | glguy | 22 | Many-Worlds Interpretation | . 340 2015-22-2 | Paul Hankin | 21 | Wizard Simulator 20XX | . 339 2021-19-2 | ecnerwala | 21 | Beacon Scanner | . 338 2019-16-2 | bluepichu | 19 | Coprocessor Conflagration | . 336 2017-23-2 | Lewin Gan | 19 | Flawed Frequency Transmission | . The longest 3 solve times were all in 2018! Shoutout to Simon Parent for solving 2 out of the top 3. This list mostly has puzzles that just take a long time to code, with Beverage Bandits as perfect example. . puzzle lb full (minutes) title . 349 2015-19-2 | 232 | Medicine for Rudolph | . 348 2015-1-2 | 186 | Not Quite Lisp | . 347 2015-22-2 | 183 | Wizard Simulator 20XX | . 346 2016-11-2 | 164 | Radioisotope Thermoelectric Generators | . 343 2018-15-2 | 143 | Beverage Bandits | . 342 2019-22-2 | 123 | Slam Shuffle | . 340 2019-18-2 | 117 | Many-Worlds Interpretation | . 338 2018-23-2 | 100 | Experimental Emergency Teleportation | . 337 2016-22-2 | 88 | Grid Computing | . 336 2018-24-2 | 87 | Immune System Simulator 20XX | . If we look at when the leaderboard capped some different puzzles show up. I feel that this list has some more algoritmic challenges (Slam Shuffle for example, but Medicine for Rudolph as well). Also 2015 shows up in the top 3. If these puzzles would be recycled in 2021 they would have been solved faster. . Overall, I feel 2018 is a strong contender for the most difficult year, with day 15 the most difficult puzzle in the history of Advent of Code! . Hope you enjoyed this analysis and see you back next year! üéÑ‚≠êüéÖ .",
            "url": "https://jvanelteren.github.io/blog/2022/01/02/analysis_aoc_stats.html",
            "relUrl": "/2022/01/02/analysis_aoc_stats.html",
            "date": " ‚Ä¢ Jan 2, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Advent of Code",
            "content": ". Remember these üéÖAdvent CalendersüéÖ where you open a door each day to find a piece of candy? Advent of Code is like that, but with coding puzzles: from 1st to 25th of December, every day a puzzle unlocks at midnight. Each puzzle has two parts where you can earn a star, so you can earn 2 stars per day, adding up to a total of 50. Since 2015 every year the amount of particpants grows, in 2020 over 150.000 people around the world have participated. You can solve the puzzles any way you like. I&#39;ve always used Python, but anything goes, even Excel (if you are brave). . I was introduced to AoC in 2018. It was a real challengeü§Ø to solve all the puzzles. In 2020 I tried to compete for the leaderboard, which meant getting up at 5:50AM 25 times in a row, which was an experience in itself. Never did I get a spot in the top 100, but I am proud to be part of the ~700 people who finished all the puzzles from 2015 onwards. . For old times sake, I&#39;ve listed my personal Top 9 most memorable puzzles of all time (2015-2020): . 9) 2019 Day 23: Category Six . A nice puzzle where you had to simulate computersüíª receiving and sending packets over a network to eachother. Memorable because I later could use it to practice using Pythonüêç Async. . 8) 2018 Day 23: Experimental Emergency Teleportation . Given a 3D room with many bots that can reach up to a certain distance, what&#39;s the spot where you can reach most bots? Seems simple, but the room is HUGE! This makes solving the puzzle a nice challenge. . 7) 2019 Day 13: Care Package . 2019 is a special year for AoC, since you eventually code your own working &#39;IntComputer&#39;. During day 13, we used this computer to play arkanoid. Later on there were more puzzles where the IntComputer was used. . 6) 2020 Day 21: Allergen Assessment . For many people probably not very memorable, but this got me the 189th spot on the leaderboardüíØ, where I normally hovered around 1600. Usage of sets in Python just came together for me in this one. . 5) 2019 Day 18: Many-Worlds Interpretation . Memorable because it was very difficult to solve with code and did it eventually on paper! You&#39;re in a maze and need collect keysüóù. The keys correspond to doors that open when you find the key. The mechanism of unlocking doors makes the amount of possible states explode. . 4) 2018 Day 17: Reservoir Research . Another one from my first year of participation. You have to simulate waterüåä falling down into buckets. Just a great puzzle to toy around with. All AoC puzzles have some kind of story to them. I found this one to be especially memorable. . 3) 2016 Day 11: Radioisotope Thermoelectric Generators . Remember that puzzle of the wolfüê∫, chickenüêî and farmerüë®‚Äçüåæ that have a boat to cross the river? That&#39;s the one, but now with 5 animals and 3 rivers. I played with lego blocks trying to find the best solution. Didn&#39;t work, got confused and in the end had to make it into a BFS, which is an algorithm that comes around frequently in AoC. . 2) 2018 Day 10: The Stars Align . A puzzle where you are presented with a set of starsüåü that are moving towards eachother. Again a simulation where at a certain point of time the stars align into a code. Animating the stars and having to zoom in into that tiny spot where they formed the code was lots of fun. . 1) 2019 Day 22: Slam Shuffle . And the number one, the only puzzle in 2019 I didn&#39;t solve in the same day. Take a deck of cardsüóÉ, apply some operations on it and identify the card in postion 2020. Easy enough right? Yes, untill for part 2 that deck consists of 119315717514047 cards and you have to apply the operations 101741582076661 times! Good luck brute forcing that. It took me around 20 hours to solve the puzzle and was so close to giving up. Such a great feeling when it finally came together. Wrote a small post on reddit on it. . I&#39;ve uploaded my solutions to GitHub. People post their solutions on the AoC subreddit, which is a great way to learn from the best. . Needless to say I highly recommend AoC! See you all December 1stüéÑ! .",
            "url": "https://jvanelteren.github.io/blog/2021/07/10/aoc.html",
            "relUrl": "/2021/07/10/aoc.html",
            "date": " ‚Ä¢ Jul 10, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Turnonderzoek op het journaal",
            "content": ". Op het NOS journaal: tweederde van turners heeft te maken met grensoverschrijdend gedrag. Als vader met een meisje op turnen krab je je dan toch even achter de oren... Maar, de interesse was gewekt en voor het lidmaatschap op te zeggen ben ik toch even het ruim 400 pagina&#39;s dikke rapport ingedoken. Uiteraard met de databril op. En dan schrik je toch wel, maar vooral van de eenzijdige journalistiek... . Waar komt die tweederde vandaan? Het journaal meldt dat het hierbij gaat om oud-sporters en actieve. Dat klopt niet, het gaat om oud sporters (van voor 2014). Deze konden een vragenlijst invullen op de website van de turnbond. De turnbond beschikte niet over de emailadressen van deze turners, dus de participanten moeten op een andere manier hun weg naar de website hebben moeten vinden. 282 deelnemers hebben de vragenlijst ingevuld. Ter referentie, in 2014 had de turnbond 241.435 leden. De onderzoekers melden zelf ook dat de resultaten niet representatief zijn en dat er geen generaliserende conclusies kunnen worden getrokken over de gehele gymsport. . Er treedt bij dit onderzoek een dubbel selectie-effect op: . Mensen met een sterke mening over het onderwerp zullen de vragenlijst eerder invullen. Vergelijk het met een onderzoek over geluidsoverlast. Welke mensen zullen hierbij reageren, degene die geluidsoverlast ervaren of niet? Om dit effect te verminderen was een alternatieve aanpak geweest om niet aan te kondigen dat dit onderzoek over GOG ging. Maar dat heeft ook weer zo z&#39;n nadelen. | 80% van de deelnemers geeft aan (semi)topsport te hebben beoefend. Van deze oud-topsporters geeft 85% aan met grensoverschrijdend gedrag te maken te hebben gehad. Bij de semi-topsporters is dit 58% en bij de breedtesporters 35%. Het hoge aandeel van topsporters in de respondenten trekt het gemiddelde omhoog naar tweederde. Beide effecten werken vertekenend als je een conclusie wilt trekken over de gehele turnsport. De auteurs benoemen het mogelijke selectie-effect. | . Er zijn ook vragenlijsten per email verstuurd, van de 180.000 turners waarvan gegevens beschikbaar waren zijn alle (semi) topsporters van na 2014 aangeschreven (8147) en 5% (7136) van de overige leden. Ongeveer 18% reageerde. Dit is een ietwat magere respons. Hieronder een gedeelte van de infographic van het rapport, deze geeft het verschil weer tussen de ervaringen van topsporters (60-70% te maken met GOG) en recreatieve sporters (15% te maken met GOG). . Het aantal respondenten vanuit de recreatieve groep is erg klein, bijvoorbeeld 21 respondenten waren volwassen recreatieve sporters. In werkelijkheid turnt 73% van de turners op recreatief niveau, niet 3% zoals bij de volwassen respondenten. Recreatieve sporters zijn dus enorm ondervertegenwoordigd in de steekproef. Wederom het selectie-effect. De onderzoekers geven aan dat &#39;de omvang van grensoverschrijdend gedrag vrijwel niet betrouwbaar is vast te stellen&#39;. . . Een heel negatief beeld dus op het journaal. Met betrekking tot de breedtesport kan je nauwelijks cijfermatige conclusies trekken, terwijl het wel wordt gepresenteerd als de turnsport als geheel. Bij wedstrijdsporters is er meer zekerheid, maar blijft het selectie-effect een grote onzekerheid. Maar het genuanceerde verhaal paste natuurlijk niet in het journaal. . Dan is er ook nog een soort positief nieuws, er wordt onderzoek geciteerd uit 2020, door NOC/NSF gepresenteerd als representatief (n=5.000). Turnen staat bij een vergelijkend onderzoek laag in de middenmoot van sporten waar mensen grensoverschrijdend gedrag hebben meegemaakt (voetbal, handbal, hockey, korfbal scoren veel hoger). Bij seksueel grensoverschrijdend gedrag staat turnen nog lager, ongeveer gelijk met &#39;schaken&#39;. Zie onder de grafiek over emotioneel grensoverschrijdend gedrag uit dat onderzoek. Hierbij is geen onderscheid gemaakt tussen top- en recreatiesport. . . Meer positief nieuws: van de respondenten geven de volwassenen het turnen gemiddeld een 8 (33% geeft een 9 of 10) en de minderjarigen met een 8,5 (54% geeft een 9 of 10). Deze score ligt bij de topsporters wat lager dan bij de recreanten. Maar komt dat door GOG of doordat topsport als minder leuk wordt ervaren? Het zou interessant zijn om deze getallen nog uit te splitsen in groepen die wel/niet GOG te maken hebben gehad. Dan kan je misschien iets zeggen over de impact van GOG/topsport op turnplezier. Hieronder de grafiek van minderjarige respondenten. . . Dan tenslotte: ik heb echt alleen naar de cijfers gekeken, dit doet niets af aan de ernstige ervaringen die turners in kwestie hebben meegemaakt. Dit is nooit acceptabel en werken aan verbetering van de sport is altijd goed. . Zolang m&#39;n dochter het leuk vindt (en nog geen topsporter is) ga ik in elk geval met gerust hart en veel plezier naar de ü§∏‚Äç‚ôÄÔ∏èturntrainingü§∏‚Äç‚ôÇÔ∏è! .",
            "url": "https://jvanelteren.github.io/blog/2021/04/29/turnen.html",
            "relUrl": "/2021/04/29/turnen.html",
            "date": " ‚Ä¢ Apr 29, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Tekst analyse van Tweede Kamer moties",
            "content": ". Nog net voor de verkiezingen deel 2 van het motie-onderzoek! Naast deze blog heb ik ook nog de StemVinder ontwikkeld om snel relevante moties te vinden. . In dit deel kijk ik naar de inhoud van de moties. Op de moties te clusteren naar onderwerp gebruikte ik in eerste instantie een bekende techniek Latent Dirichlet Allocation, maar via een gelukkig toeval kwam ik achter een gloednieuwe aanpak die veel beter werkt! Longhow Lam heeft deze toegepast op kamerdebatten van de Tweede Kamer. . Het Top2Vec algoritme probeert soortgelijke woorden en documenten te clusteren en hieruit onderwerpen te destilleren. In de wordcloud hierboven staan heel generieke woorden die in veel moties voorkomen. Deze zijn niet onderscheidend en worden er automatisch uitgefilterd door het algoritme. Echt weer zo&#39;n voorbeeld van een doorbraak in machine learning die sneller en beter werkt waardoor oude technieken bij het grofvuil kunnen. . Bij de moties worden er ongeveer 250 topics ge√Ødentificeerd. In deze onderwerpen zit wat overlap en het is een beetje lastig visualiseren, dus uiteindelijk heb ik die voor deze blogpost samengevoegd tot 15. Onderop deze blog staan wordclouds van de 15 onderwerpen. . Welk soort onderwerpen staan op de agenda? . Eerst kijken we naar de ontwikkeling van de onderwerpen van de ingediende moties. We weten al dat het absoluut aantal moties stijgt, dus heb ik gekeken naar de relatieve verdeling van de onderwerpen. . Opvallend dat de verhoudingen redelijk stabiel zijn! Je ziet dat in de loop van de tijd klimaat en energie, milieu en regelgeving (heel veel coronaregels zitten hier ook in gecategoriseerd), sociale zaken en wonen omhoog gaan. Omlaag gaan landbouw en dierenwelzijn, natuur en gaswinning, onderwijs en openbaar vervoer. Binnen de onderwerpen zijn natuurlijk wel verschuivingen waar het precies over gaat. We onderzoeken nu de ingediende moties tijdens de afgelopen Tweede Kamer periode. . Meest actieve partijen per onderwerp . We onderzoeken welke partijen het meest actief zijn door op drie manieren naar de data te kijken: . Aantal ingediende moties (per partij per onderwerp) | Aantal succesvolle moties | Aantal succesvolle moties per zetel | In bovenstaande grafiek zien we bijvoorbeeld dat op onderwijs de meeste moties worden ingediend door Groenlinks (1 in de grafiek), gevolgd door de SP (2), PvdA (3) en D66 (4). Een punt van aandacht is dat deze analyse niet aangeeft wat de partijen met de moties willen bereiken, bijvoorbeeld op openbaar vervoer wil VVD waarschijnlijk heel iets anders bereiken dan SP. . PVV is erg actief op justitie, en de PvdD op klimaat, dierenwelzijn milieu en natuur. Ook de enorme output van de SP valt op! Maar ingediend is niet hetzelfde als aangenomen, dat wordt de volgende grafiek: . Wat betreft het aantal succesvolle moties dan zien we daar ineens vier partijen bovendrijven: CDA, D66, GroenLinks en de VVD. Veel regeringspartijen, dat is logisch want die hebben een meerderheid. Ook vind ik het opvallend dat PvdA echt op sociale zaken en het pensioenstelsel succesvol is en GroenLinks op de andere onderwerpen. . Nu kijken we naar het aantal succesvolle moties per zetel . Met je stem koop je op 17 maart politieke invloed. Dit overzicht geeft weer hoeveel &#39;waar je voor je geld&#39; krijgt, hoeveel succesvolle moties een zetel van een partij er doorheen krijgt per onderwerp. Het is weer een heel ander beeld: de christelijke partijen doen het heel erg goed (even gecheckt en inderdaad het Dik-Faber effect bij de ChristenUnie op Zorg, Voordewind op Buitenlandse zaken) en de SP komt een stuk minder terug. Opvallend ook dat D66 relatief weinig scoort op Onderwijs. Partijen die minder in de prijzen vallen zijn FvD (nr 5 op Europese Unie), de PVV nergens en de VVD op financiele sector (nr 5). Bij de VVD is dit te verklaren doordat ze veel zetels bekleedt. . Waar richten de partijen zich op? . In bovenstaande grafieken hebben we de partijen onderling vergeleken. Nu kijken we per partij op welk vlak ze het meest actief zijn . Als een partij een aantal heel grote bollen heeft betekent dit dat de partij zich heel erg richt op dit onderwerp. Zijn er geen grote bollen binnen een partij is de inzet meer over de onderwerpen verspreid. Algemene zaken, Onderwijs en Zorg krijgen bij veel partijen veel aandacht. Daarnaast hebben FvD, PVV, 50PLUS en de PvdD een heel uitgesproken profiel. In het achterliggende notebook heb ik ook nog gekeken naar de ontwikkelingen per partij van de afgelopen 4 kamerperiodes. . Stemgedrag per onderwerp . Dan toch nog eens proberen het stemgedrag te visualiseren. Als de VVD iets indient voor de Financiele Sector betekent dit namelijk iets heel anders dan als de SP dat doet. In onderstaande plots staat per onderwerp het stemgedrag gevisualiseerd. Positief of negatief zegt niets, het gaat om partijen die dichtbij of ver weg van elkaar staan. PvdD en VVD vormen meestal de uitersten en verschillen dus het meeste op stemgedrag. Deze grafieken verklaren meestal zo&#39;n 35%-55% van de variatie in het stemgedrag. Let op: het is dus een versimpeling van de werkelijkheid! . &#39;#&#39; geeft het aantal moties aan en &#39;%&#39; het percentage dat deze visualisatie verklaart. Het meest opvallend is dat FvD en PVV soms in het midden zitten en soms aan de rechterkant. Bij de Europese Unie mengen SP, PvdD en de SGP zich hier ook in. Als het gaat om pensioenen zitten ze juist meer aan de linkerkant. De groep PvdD, SP, GroenLinks, PvdA en DENK zit standaard links, alleen wederom bij de EU en pensioenstelsel wordt gehusseld. 50PLUS zit vaak in het midden, behalve bij pensioenstelsel. . Onderzoek naar klimaat . Omdat ik denk dat klimaat de grootste uitdaging is voor de mensheid heb ik hier de subonderwerpen nog eens doorgenomen. Natuur en milieu zijn natuurlijk ook heel erg belangrijke onderwerpen, maar toch besloten het even bij het klimaat te houden. . De vraag is op welke partij je stemt: PvdD dient enorm veel moties in en bepaalt hier wel het debat mee. Maar D66 en GroenLinks dienen dan weer meer succesvolle moties in. . En hier houdt het een beetje op, voor een stemadvies moet je namelijk uiteindelijk toch weten waar de partijen voor staan. Laat ik daar nu net de StemVinder voor hebben gemaakt. Veel plezier ermee! . . Tip: Bedankt Dimo Angelov, bedenker en ontwikkelaar van Top2Vec, Longhow Lam voor de LinkedIn blogpost en Willem Glasbergen voor de tip! Zonder deze drie was het niet gelukt :-) . Bijlage: classificering van de onderwerpen .",
            "url": "https://jvanelteren.github.io/blog/2021/03/07/kamermoties_topics.html",
            "relUrl": "/2021/03/07/kamermoties_topics.html",
            "date": " ‚Ä¢ Mar 7, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Data-analyse Tweede Kamer moties",
            "content": ". De verkiezingen komen er weer aan, en de Tweede Kamer heeft een open data portaal. Daar heb ik eens fijn gebruik van gemaakt en alle moties vanaf 2009 gedownload. Het zijn er om precies te zijn 29514 en in dit blog kijk ik of er interessante inzichten uit te halen zijn. . Ontwikkeling van het aantal moties . Het aantal moties stijgt, met name het aantal aangenomen moties. In verkiezingsjaren (2010, 2012 en 2017) ligt het aantal moties duidelijk lager. . Moties die worden aangenomen halen meestal rond de 120 stemmen. Moties die het niet halen blijven meestal rond de 50 stemmen hangen. Eigenlijk zegt zo&#39;n gemiddelde niet zoveel en kan je beter naar de verdeling van het aantal stemmen voor kijken, dat doen we nu met een histogram per kabinetsperiode. . In de histogrammen gaat het vooral om de verdeling van de moties tijdens de kamerperiodes. . Balkenende IV: een piekje van moties die nauwelijks stemmen krijgen (waarschijnlijk protestmoties), een grote piek met moties die rond de 35 stemmen blijven hangen en een piek met unaniem aangenomen moties | Rutte I: relatief veel moties die het nipt wel of juist niet haalden | Rutte II: veel afgewezen moties | Rutte III: hele grote piek in het aantal unaniem aangenomen moties. Dit lijken er ook steeds meer te worden (500 in 2018, 700 in 2019 en 900 in 2020) | . Meestal worden moties ingediend door 1 partij, maar soms zijn er medeindieners. Sinds 2008 is er √©√©n special snowflake motie, met maar liefst 16 medeindieners. Kennelijk stond de hele kamer achter een reddingsplan voor VDL Nedcar. . Welke partij is de &#39;tegenpartij&#39;? . Logischerwijs steunt de oppositie de meeste moties, terwijl de regering vaak tegen stemt. De VVD blokkeert de meeste moties. Tijdens Rutte I en II waren deze verschillen nog groter. . Welke partijen dienen het meeste moties in en hoe succesvol zijn ze? . In bovenstaande grafiek zijn de partijen op elkaar gestapeld en is te zien dat het aantal succesvolle moties onder Rutte III sterk is gestegen. De stijging komt vooral door VVD, CDA en Groenlinks. . Deze visualisatie geeft weer hoe succesvol partijen zijn geweest tijdens de verschillende kamerperiodes. Je ziet bijvoorbeeld de PVV, PvdD en SP als partijen met veel moties, maar weinig succesvolle. Ook worden de moties van regeringspartijen vaker aangenomen. Dit komt natuurlijk doordat ze met de regeringspartijen een meerderheid hebben in de TK. Laten we nu eens kijken hoe deze grafiek eruit ziet per zetel, om een &#39;productiviteit&#39; te meten. . Opvallend vind ik het erg lage aantal moties van de VVD per zetel. Het is natuurlijk ook de partij met het hoogste aantal zetels, maar toch. De PvdA is na Rutte II losgegaan, terwijl Groenlinks iets minder indient, maar wel succesvoller is. PvdD dient het meeste moties in per zetel per jaar. Ook SGP en ChistenUnie zijn behoorlijk succesvol per zetel. . Wie zijn de &#39;motiekanonnen&#39; van de Tweede Kamer? . Wie is nu het meest &#39;succesvolle&#39; kamerlid? . De Producent: Lammert van Raan van PvdD dient maar liefst 86 moties in per jaar, hierbij blijft hij Lisa Westerveld van GroenLinks ruim voor (66 per jaar). | De Winnaar: Deze gaat ruimschoots naar Carla Dik-Faber van de ChristenUnie. Zij is met 41 aangenomen moties verreweg het succesvolst. Joba van den Berg-Jansen (CDA) staat op plek twee met 31 successen per jaar, op de voet gevolgd door wederom Lisa Westerveld (30). | De Samenwerker: Kijken we naar de politicus die het meeste moties heeft mede-ingediend staat daar wederom Dik-Faber maar liefst 94 keer als mede-indiener vermeld. In de code heb ik nog volledige top 10 lijstjes per kamerperiode bijgevoegd voor de geinteresseerden. | . Welke partijen werken samen? . Duidelijk is hier te zien dat de regeringspartijen vaak samen moties indienen. Van de oppostiepartijen zijn de PvdA, GroenLinks en de SP vaak mede indiener van elkaars moties. . Au! Dat doet pijn bij FvD! Als we kijken naar het stemgedrag stemmen bijna alle partijen tegen FvD, behalve PVV en Groep Krol. Van de oppositiepartijen krijgen alleen SGP, PvdA en Groenlinks regelmatig steun van de regeringspartijen. . Welke partijen lijken het meeste op elkaar qua stemgedrag? . In bovenstaande grafiek is het stemgedrag van alle partijen platgeslagen op √©√©n as met een Principal Component Analaysis. Deze as verklaart 40% van het stemgedrag. Of de bar positief of negatief is maakt niet uit, het gaat erom dat vergelijkbare partijen bij elkaar in de buurt liggen. Kennelijk liggen VVD en PvdD het meest van elkaar verwijderd. . Hieronder visualiseren we het stemgedrag op twee assen. Op deze manier kunnen zo&#39;n 60% van het stemgedrag beschrijven (niet 100%!). Als twee partijen vlak bij elkaar liggen wil dus niet zeggen dat ze altijd hetzelfde stemmen. De horizontale as is groter omdat deze meer van het stemgedrag verklaart. . De x-as lijkt toepasselijk de politieke links-rechts as te beschrijven. De y-as is iets lastiger te duiden, iets met samenwerken vs alleenstaan? Waarschijnlijk komt dit doordat FvD en PVV vaak moties indienen die zij alleen steunen maar de rest van de partijen niet zoals we hebben gezien. . Er zijn grofweg 3 clusters te onderscheiden: . de oppositie linksonder | de regeringspartijen rechtsonder | PVV en FvD bovenaan. | . Ik heb het ook nog met de afgelopen kabinetten vergeleken en komt erop neer dat de ChristenUnie en D66 vaak iets meer naar het midden zitten. In die zin is een &#39;linkse samenwerking&#39; van GroenLinks logischer met SP dan met D66. SGP zit vaak vlakbij de regeringspartijen. . In een volgend blog (dat ik hopelijk nog voor de verkiezingen publiceer) bekijk ik de inhoud van de moties. Kijken of er trends zijn in onderwerpen en welke partij het meest actief is op bepaalde onderwerpen. . . Note: Ik heb enkele visualisaties in de blog achterwege gelaten om het nog enigzins leesbaar te houden. Op Google Colab is deze beschikbaar. De code staat op GitHub (Python) .",
            "url": "https://jvanelteren.github.io/blog/2021/02/20/kamermotiesEDA.html",
            "relUrl": "/2021/02/20/kamermotiesEDA.html",
            "date": " ‚Ä¢ Feb 20, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Face2Age",
            "content": ". This blog is about predicting someone‚Äôs age by their face. I&#39;ve also made an webpage where you can try to beat the computer. . Deep learning has seen incredible results the last couple of year. As long as you have a large enough dataset, it you can transform any input to any output. A couple of examples: . Image classification, where you map an image to a label (input an image of a frog, computer outputs ‚Äòfrog‚Äô) | Sentence generation (if I start a sentence with ‚ÄòToday, the weather is‚Äô, computer outputs ‚Äògreat, let&#39;s take a walk‚Äô. | Recommender system (which is the next video that will be most likely to keep the user watching) As an aside, deep learning is not without it‚Äôs ethical problems, for example these social media recommender systems have a tendency to radicalize people, since that maximizes their &#39;engagement&#39; to the platform. | . In this project, I‚Äôve taken on a image regression problem. It‚Äôs a nice problem, because the answer is not always obvious: some people look older or younger than they really are. By showing the computer model examples and giving feedback how wrong it is on its prediction, the model is improving. We don‚Äôt have to explain anything about how an old or young person looks like. Can you imagine how difficult it would be to program how to recognize wrinkles? This is essentially the wonder of neural networks. . When training a model, an important part is the performance metric. For this task of guessing someone‚Äôs age, I‚Äôve chosen Mean Absolute Error, basically how many years you‚Äôve guessed wrong. A prediction of 12 on an actual age of 10 means the MAE is 2, just as a prediction of 8 also has an MAE of 2. . The dataset contains about 10.000 images, I‚Äôve trained the model on 70% of the dataset. That leaves about 3k images which the model has not seen. We use this to test it‚Äôs performance. In theory, this performance will generalize to other unseen images. In practice that remains to be seen, since real life images can be much messier, e.g. in quality, zoom level and background. . Below you can see it getting better over time. The horizontal axis displays how many times we feed the training set to the model. The left graph shows performance on the training set, the right graph on the test set. Initially, it‚Äôs off by about 11 years, and slowly converging to a MAE of 2 years. But taking the performance on the training dataset is cheating, we are interested in it‚Äôs performance on unseen images! The performance there converges to around 4.2. . . Let&#39;s check out predictions on some random images in the test set. In the title the actual age and the predicted age by the model. . That looks pretty good! To take a more general approach, let&#39;s plot the all the images from the test set in a graph. . There are definitely some errors, but overall it seems reasonable. It&#39;s also interesting to plot the faces where the error was largest. . In most of the cases the model was simply off, but there are also faces which look much older or younger, or very blurry ones. Which highlights the importance of understanding the dataset and potentially removing outliers from it. . Another approach is to visualize the average error by age. . The error gets larger as someone gets older, which makes perfect sense: when you see a baby you are not going to guess wrong by more then 5 years, but for someone age 50 that is more difficult. . You could argue for a slight improvement in the predictions with ages &gt; 60, but it could also be an anomaly. There are few really old faces in the dataset, which could be of influence. There are also 300 images of babies age 0 in the dataset, which I removed from the second chart to have a better visualisation. . I‚Äôve build a webpage where you can try out if you can beat the computer, or even upload a selfie for fun to see how old the computer thinks you are. Please take the results with a grain of salt. I‚Äôve taken some selfies and the computer estimated me around 27 to 42, which is ballpark accurate. However, a condolence card of my grandmother age 92 was classified as 62, and although she did look young, 62 was an underestimation. . I‚Äôve had much fun with this project. I hope you like it as well and will try out the application. No guarantees it will be online indefinitely by the way. . . Note: Technical details on how it was build: Pytorch, Pretrained resnet-18 model. Application runs on Google Cloud Platform, with a Nginx and Gunicorn running in Docker container. Python backend in Fastapi. Code available on Github, dataset on Kaggle .",
            "url": "https://jvanelteren.github.io/blog/2020/11/24/face2age.html",
            "relUrl": "/2020/11/24/face2age.html",
            "date": " ‚Ä¢ Nov 24, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Current preferred data science setup",
            "content": "I‚Äôve spend some time tinkering with getting a preferred data science stack up. In this post I‚Äôm detailing the choices made and could also help you get started on GCP. If you just want to start with programming, go to Google Colab and you&#39;re set to go. . . The data science setup is now made up of: . All development in Python (installed via Miniconda), with Pytorch and Fast.ai for deep learning | A personal computer with Windows 10, VSCode with Jupyter notebooks functionality | Google Cloud Platform with a Docker container running Linux Ubuntu | Github for storing the codebase and a github action based blog running fastpages | . For me this works best at the moment. Some remarks on tradeoffs. . Python vs other languages. Python is todays language of choice for data science. It&#39;s just so simple to express ideas in code. Also there are just so many packages available with useful functionality that the whole world is basically an import statement away. Maybe I‚Äôll learn Julia, Kotlin or Swift once, but for now I‚Äôm set. . | Pytorch vs TensorFlow: Pytorch is so much easier compared to Tensorflow. I remember doing an introduction on Tensorflow and I found it difficult to grasp. . | Pytorch vs Fast.ai. Fast.ai is kind of the Keras of Pytorch. It has been a blessing and I do highly recommend it. The online course is great. Also you can get a deeplearning model running in no time. But it‚Äôs also an extra layer of abstraction to remember on top of trying to learn Pytorch. So right now I‚Äôm now mostly using with Pytorch and Fast.ai once in a while. . | Windows vs Linux: OK for data science everyone says Linux is the go to, but I‚Äôm just so accustomed to Windows! I can definitely see the advantages of Linux and are slowly gravitating towards using a command line interface more. Windows made a big step with WSL2, so you can now run Linux from within Windows easily, so I did install Ubuntu locally. Maybe in the future I‚Äôll switch fully to Linux, but for now this is working fine. . | VSCode vs Jupyter Notebooks. In my opinion the setup of running notebooks within VSCode combines the advantages of a fully fledged IDE with the agile development that notebooks are known for. . | Having an own computer vs doing everything in the cloud. Working in the cloud always has a startup of a couple of minutes. My time is limited, so I do prefer to open VSCode and start coding right away. When I need more compute I use the cloud. . | GCP vs other cloud platforms. This decision was taken based on the $300 free credit you get with GCP. . | Github: Initially I had all the code on my local computer and I used Git for version control. Now that I sometimes iterate between working locally and in the cloud, I store the main branch on Github and push/pull from whichever environment I‚Äôm working on. . | Fastpages: First I started on Medium, but fastpages is a live saver for publishing from notebooks. It makes it actually fun to blog, instead of a chore duplicating your work in a blog article . | Docker: For reproducibility, Docker is king. For cloud computing I think it‚Äôs the best way. You just make a Dockerfile and know what you will get. Also it can make the steps to deployment easier. . | App deployment: Don‚Äôt know what the best is yet. Have tried Render, and could get a webserver it to work with GCP as well. You can even deploy on Binder with a notebook. Guess this one depends on the use case. . | . The remainer of the post is dedicated to helping you out with setting up GCP with Docker. Some things you need: . The CLI command from Windows to get a VM running | A startup script to make sure the VM runs the container | A Dockerfile to build a docker image from | . Let&#39;s start with the CLI command . gcloud beta compute instances create gpu ` --zone=us-central1-c ` --machine-type=n1-standard-8 ` --subnet=default ` --service-account=YOURSERVICEACCOUNT-compute@developer.gserviceaccount.com ` --image-family=common-cu110 ` --image-project=deeplearning-platform-release ` --boot-disk-size=50GB ` --scopes=https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/devstorage.full_control ` --accelerator=type=nvidia-tesla-k80,count=1 ` --metadata=install-nvidia-driver=True ` --maintenance-policy=TERMINATE ` --metadata-from-file startup-script=startup-gpu.sh ` --preemptible . You can create a GCP VM from the command line interface (CLI) or through the browser based console. Play around with the console to get an idea. Then, on the bottom click gcloud command to see the CLI command to copy in your terminal . This command uses ` at end of line since it&#39;s run from Windows Powershell. If you use Linux, use backslash . Don&#39;t use Container Optimizer OS, as of november 2020 they dont install nvidia container runtime, meaning it&#39;s difficult to make use of the GPU inside the container. An approach that works is to use a data science image like common-cu110 as I&#39;ve used here. . The K80 is the cheapest GPU, good for experimenting. . Also, use --preemtible. You&#39;re VM may be stopped unexpectedly, but it&#39;s about 66% cheaper! . Next up is the startup script... . # first some waiting until gpu drivers are truly installed while ! [[ -x &quot;$(command -v nvidia-smi)&quot; ]]; do echo &quot;sleep to check&quot; sleep 5s done echo &quot;nvidia-smi is installed&quot; while [[ $(command nvidia-smi| cut -c1-10) == &quot;NVIDIA-SMI&quot;* ]]; do echo &quot;$(command nvidia-smi)&quot; echo &quot;sleeping to check&quot; sleep 5s done echo &quot;$(command nvidia-smi)&quot; echo &quot;nvidia-smi drivers are up&quot; # if you have a persistent disk you can use this to automatically mount it, otherwise remove it if [ ! -d &quot;/mnt/disks/storage&quot; ] then sudo mkdir -p /mnt/disks/storage sudo mount -o discard,defaults /dev/sdb /mnt/disks/storage sudo chmod a+w /mnt/disks/storage sudo cp /etc/fstab /etc/fstab.backup sudo blkid /dev/sdb echo UUID=`sudo blkid -s UUID -o value /dev/sdb` /mnt/disks/storage ext4 discard,defaults,nofail 0 2 | sudo tee -a /etc/fstab echo &quot;mounting complete &quot; else echo &quot;not first startup&quot; fi # startup your Docker container, with port 6006 mapped to Docker for Tensorboard gcloud auth configure-docker docker run -d -p 0.0.0.0:6006:6006 --gpus all --ipc=&quot;host&quot; -v /mnt/disks/storage:/ds gcr.io/delta-deck-285906/dockerfile echo &#39;Docker run with GPUs&#39; . The first part of the startup script is mainly to wait until the gpu drivers are properly installed. Otherwise, docker run --gpus all will throw an error. Additionally, I like to use a persistent disk. To avoid the hassle of having to mount it every time I startup a new VM, this script does the work for you. Finally the most important is the Docker run instruction. It opens your container with GPU support. The first time you start up your VM it will take some minutes, but afterwards it&#39;s almost immediate. . After this I like to connect to the running container with Vscode Remote-Container Attach to running container command. Checkout the Vscode docs for how to set this up. Basically you need to put the external ip of the VM into your SSH config file and add a line to your settings.json . &quot;docker.host&quot;: &quot;ssh://YOURUSER@xxx.xxx.xxx.xxx&quot;, . Host xxx.xxx.xxx.xxx HostName xxx.xxx.xxx.xxx.xxx IdentityFile localpath/to/publicsshkey User YOURUSER StrictHostKeyChecking no . One final file to share: the Dockerfile which you can use to build your Docker image . FROM nvidia/cuda:10.2-runtime-ubuntu18.04 ##Set environment variables ENV LANG=C.UTF-8 LC_ALL=C.UTF-8 RUN apt-get update --fix-missing &amp;&amp; apt-get install -y wget byobu curl git-core python3-virtualenv unzip &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/* RUN wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-py38_4.8.3-Linux-x86_64.sh -O ~/miniconda.sh &amp;&amp; /bin/bash ~/miniconda.sh -b -p /opt/conda &amp;&amp; rm ~/miniconda.sh &amp;&amp; ln -s /opt/conda/etc/profile.d/conda.sh /etc/profile.d/conda.sh &amp;&amp; echo &quot;. /opt/conda/etc/profile.d/conda.sh&quot; &gt;&gt; ~/.bashrc &amp;&amp; echo &quot;conda activate base&quot; &gt;&gt; ~/.bashrc ENV PATH /opt/conda/bin:$PATH RUN pip --no-cache-dir install --upgrade altair ipykernel kaggle fastbook tensorboard diskcache &amp;&amp; conda install -c fastai -c pytorch fastai &amp;&amp; pip uninstall -y pillow &amp;&amp; pip install pillow-simd --upgrade &amp;&amp; mkdir -p ds/.kaggle &amp;&amp; git clone https://github.com/fastai/fastbook.git /ds/fastbook # Open Ports for Jupyter # EXPOSE 7745 #Setup File System ENV HOME=/ds ENV SHELL=/bin/bash ENV KAGGLE_CONFIG_DIR=/ds/.kaggle VOLUME /ds WORKDIR /ds # Make sure the container stays open CMD tail -f /dev/null . The Docker tutorial by Hamel Husain has helped me greatly, especially the advice to use someone elses dockerfile and start making it your own by gradually adapting. The above dockerfile is based upon his actually. . That&#39;s it, hope it has helped you! .",
            "url": "https://jvanelteren.github.io/blog/2020/10/31/data_science_setup.html",
            "relUrl": "/2020/10/31/data_science_setup.html",
            "date": " ‚Ä¢ Oct 31, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Red-Black trees",
            "content": "After playing around with red-black trees for some time, I‚Äôve grown to really like them, but also hate them at the same time! I&#39;ll explain in this blog why. To understand what a red-black tree is, we‚Äôll first have to touch upon the concept of a binary search tree. The binary search tree is a method of ordering items that can be compared to each other. The easiest example is of course numbers (1 &lt; 2), other object such as letters (a &lt; b) or words (short &lt; longerword) can also be compared. . A binary tree is very simple and I had fun making one with my six year old daughter. She came up with a list of numbers and together we added them to the tree. The root of the tree is the first item you start with. Next, to add another item you simply check if the item is smaller or larger than the root. If it‚Äôs smaller it gets stored into the left branch, if it‚Äôs larger it goes to the right branch. A node in the tree can have only one branch on each side. Therefore the tree will have to get deeper when more nodes are added. As an example, a tree with 3 layers holds a maximum of 1+2+4 = 7 nodes. Below an example, where it takes three steps to reach 5,14 and 55 and four steps to reach 62 and 66. These nodes are the edge of the tree and are called leaves. . The advantage of binary search trees is that the items are ordered. For example, you can easily lookup the minimum (just always go left from the root). But also finding an item can be very quick, which is expressed by the number of steps from the root. It makes sense, if you are interested in the left side of the tree, you no longer need to search the right side. . But think about a scenario where you insert numbers in order, ascending. The tree would only have right branches! This effectively means you are just storing a list. Now for a small tree (as the one below), that is no problem, but if you are storing a million items this way, you would have to search a million items before inserting the next number. If the tree would have been balanced, it would only take about 20 steps from the root to any leaf (1 million log base 2). . This is where red-black trees come in. They are self-balancing to solve the above problem. In a red-black tree, items are colored in two colors. You‚Äôve guessed it, red or black. There are a couple of rules: . The root is always black | While going from root to any leaf, you‚Äôll never pass two consecutive red items | The amount of black items you pass while going to an end of the tree is the same for each leaf of the tree. | . To preserve these properties insertion and removal can require certain operations, such as recoloring certain items, or rotating part of the tree. And this is where my love and hate comes in. It‚Äôs awesome to see the different shapes the tree can take while balancing. Even the root of the tree can change in the process. A couple of examples: . In the above figure, numbers 0 to 10 were inserted in order. The graph shows that the redblack tree has been rotated to now have 3 as root (no longer the 0 it started with initially). Also the paths from the root (3) to the leaves (0,2,4,6,8 and 9) all cross exactly 3 black nodes! . If we insert 50 items in order, a nice balanced tree appears . to_insert = list(range(50)) RBTree(to_insert,silent=True).draw() . When we randomize the insertion order a completely different tree arises, but still it&#39;s nicely balanced. . random.shuffle(to_insert) RBTree(to_insert,silent=True).draw() . I think this looks elegant. However, it‚Äôs known that redblack trees can be difficult to implement and indeed it&#39;s been an absolute pain to code the algorithms, with some difficult debugging to take care of all the edge cases to make sure the code runs correctly. More detailes of all the cases you can encounter at Wikipedia. I‚Äôve gained new appreciation for programming concepts such as unit testing, refactoring, and plain old careful reading of the specification. Seeing it work has made this project worth it! . After some reading, I‚Äôve also come across the treap (tree-heap), which is basically using random numbers to make the tree structure as if the items would have been inserted in random order. Which will make the tree balanced with a high probablility. . To illustrate the randomness, I&#39;ve twice made a treap with 50 items inserted in order. The resulting trees are different, which does not happen with red-black trees when the insertion order is the same. Treaps look much different then the red-black trees as well. . Treaps are much simpler to implement and outperform red-black trees on insertion, search and deletion, but due to their randomized nature are less consistent. Also red-black trees look nicer in my opinion. . That&#39;s it, hope you enjoyed it this exploration of trees! . . Tip: This page has a nice animation how red-black trees are build. Additionally, Wikipedia has more information about binary search trees, red black trees and treaps .",
            "url": "https://jvanelteren.github.io/blog/2020/09/12/redblacktree.html",
            "relUrl": "/2020/09/12/redblacktree.html",
            "date": " ‚Ä¢ Sep 12, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "Predicting the value of a house",
            "content": "Recently I‚Äôve made my way into Kaggle. If it‚Äôs new for you, I highly recommend checking it out. Kaggle is a platform where organizations host data science competitions. They come up with a data science challenge, make the data available to Kaggle users, and many data scientist worldwide compete to get the highest score on the leaderboard. After a defined period the competition ends and the winner is awarded with a (monetary) price. . Participants also share their code (kernels), and have discussions on the data. This makes it an excellent platform to learn. The competitions can be a bit intimidating, since it can have extremely large datasets (100GB upwards), the objectives can be challenging (imaging, audio, text, combinations) and figuring out how to submit is not always trivial. But of course you can start with simpler competitions such as the classic Titanic example. . Since I‚Äôm quite familiar with tabular data I decided to give the housing competition a try. The training data consists of many features describing about 1500 houses and their selling price. After numerous experiments I ended up with a top 3% score on the leaderboard before throwing in the proverbial towel. The rush of inching up the leaderboard made it a great experience! . Afterwards I wrote about the main insights, learnings and questions . Next up: probably a imaging competition with Pytorch or fast.ai .",
            "url": "https://jvanelteren.github.io/blog/2020/07/26/housing.html",
            "relUrl": "/2020/07/26/housing.html",
            "date": " ‚Ä¢ Jul 26, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "Exploring flight patterns above The Netherlands",
            "content": "Some years ago I woke up early because of a loud aircraft flying over. Couldn‚Äôt get back to sleep and decided to use these precious early hours to visualize the air traffic around Hilversum. . Every aircraft is equipped with a device called a transponder that transmits flight data about the flight into the air. Organizations like OpenSky aggregate these data and make them available. Below a screenshot of the result, you can see the tracks and some information about the flight is displayed. . . But when revisiting this initial project, I felt there were more opportunities. I obtained air traffic above the Netherlands from February to April (monday&#39;s only), resulting in 11 full days of traffic. Below a first visualisation. . When reading this post on a computer, I recommend zooming in with ctrl + mousewheel. On mobile it&#39;s with your fingers :) Use the buttons on the right to zoom in on the map. If you see a bright white line over your hometown, there is probably a lot of air traffic flying over. . Panel . . Let&#39;s see if there are more interesting patterns and visualisations. First we split the traffic by altitude. . Start or landing | Departure/arrival | Aircraft passing | . Red: The lowest flying traffic. Airfields such as Eelde, Eindhoven, Dusseldorf and Brussels are visible. | Blue: All the complex movements of traffic in and out of Amsterdam. These are standard routes being flown to keep the traffic manageable, so called STARs and SIDs. | Green: The highest flying aircraft are passing over in mostly straight tracks. | . There are more properties in the data, such as altitude, vertical speed and velocity. . Vertical rate (red=desc) | Mean altitude per 1000m | Mean velocity, dark=slow | . Left: all the arriving flights are red and departures are blue. | Middle: This disco shows aircraft climbing or descending. The colormap is increasing with 1000m per color, starting from red for 0-1000m. Compare it with the left graph: departing flights are quickly climbing to purple, whereas arrivals are flying lower longer. The green to yellow transitions indicate the points where arrival flights are converging for their approach. | Right: the average speed of the aircraft. Also here you see arrival routes are darker (slower) than departures. | . And because COVID-19 is here, let&#39;s plot the data of the past weeks. . 2020-03-09 | 2020-03-16 | 2020-03-23 | 2020-03-30 | 2020-04-06 | 2020-04-13 | . &#39;Normally&#39; there are 2700 flights above the Netherlands (including some North Sea) with a total airtime of 840 hours per day. That is the equivalent of about 35 aircraft flying continuously. The graph shows the dramatic slowdown to about 1/8 of the original volume. . The firelike image on the left side is slowly turning into a collection of night flies: the slowdown of traffic can be easily seen. This has been analyzed more extensively here. . I also went through callsigns that occur most often. Grouping different types of traffic results in some interesting patterns. A small quiz: which pattern belongs to: . The coastguard | Aerial photography | Military flights | Emergency care flights (trauma) | Police helicopters | Commercial helicopter flights | . Answers on the bottom of the post. . A | B | C | . D | E | F | . Let&#39;s end with some visualisations with a certain shade of blue. What type of flights do they represent? . | | | . That&#39;s it, I had fun visualizing all of this, hope you enjoyed reading it! . Answers to the above: . A = Police helicopters. Lots of hovering probably. To the east the German police helicopters, with callsign HUMMEL. | B = Commercial helicopter flights. They mostly start from airfied Den Helder, flying personell to offshore rigs | C = Emergency medical flights. With callsign LIFELN (lifeliner), these helicopters are stationed in Amsterdam, Groningen, Rotterdam and Eindhoven. | D = Aerial photography. To capture the landscape below, these flights often have dense tracks flying back and forth. | E = Coast Guard, with callsign NCG | F = Military. In april a Boeing E-3 Sentry departed from NATO Air Base Geilenkirchen with probably a surveillance training mission. | . And the blues represent our flagship carrier KLM! If you want you can download the higher resolution images . . Tip: Thanks to OpenSky, Datashader and some wonderful tutorials on the internet, e.g. US Census and PyViz. I used code from these examples as well. . . Note: Here you can find my other posts .",
            "url": "https://jvanelteren.github.io/blog/2020/04/22/flights_above_nl.html",
            "relUrl": "/2020/04/22/flights_above_nl.html",
            "date": " ‚Ä¢ Apr 22, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "Ontwikkeling positieve COVID19 testuitslagen",
            "content": "Update 31 maart: Het RIVM is overgegaan op een ander type data, namelijk het aantal ziekenhuisopnames per gemeente, alleen zonder historie te publiceren. Hiermee komt er een einde aan deze visualisatie. Misschien ga ik de ziekenhuisopnames nog een keer visualiseren. . Update 18 april: uiteindelijk is de beste informatie de oversterfte per week. Deze is te vinden op de site van het CBS . Dagelijks publiceert het RIVM de inmiddels welbekende testkaart met daarop het aantal mensen dat per 100.000 inwoners in de gemeente positief is getest op Covid-19. Het leek me interessant om het verloop per gemeente te visualiseren. . Hieronder zie je drie grafieken: . Aantal: Totaal aantal positieve testcases (cumulatief) | Relatief: Totaal aantal positieve testcases per 100.000 inwoners | Groei: Toename van het aantal gevallen ten opzichte van 4 dagen geleden. Factor 0 betekent geen extra gevallen, factor 1 betekent een verdubbeling en factor 2 betekent dat er 2x zoveel cases bij zijn gekomen als dat er 4 dagen geleden waren (een verdrievoudiging van het totaal aantal gevallen). | . Je kan met de slider het verloop van de epidemie volgen. Zoom in als je hem moeilijk te pakken krijgt. Dag 0 is 3 maart, dit was de eerste dag waarvan ik data kon terug vinden op de site van het RIVM. De laatste dag is 30 maart. . Tenslotte nog een mogelijkheid om het verloop in een specifieke gemeente te bekijken . . Important: Omdat in Nederland lang niet alle gevallen worden getest ligt het werkelijke aantal cases waarschijnlijk veel hoger. Weinig cases in jouw gemeente wil niet zeggen dat er niet meer gevallen zijn! Ook zal bijvoorbeeld een ziekenhuis in de gemeente de aantallen beinvloeden vanwege relatief vaker geteste zorgmedewerkers. Pas als er in Nederland veel meer gaat wordt getest kan je er echt conclusies aan verbinden. Landelijk zeggen IC opnames momenteel meer. . . Warning: Je ziet dat sommige lijntjes heel erg stijl omhoog gaan, dat moeten we proberen te verminderen. Houdt je dus aan de maatregelen en adviezen. . . Note: Ik ben geen specialist en heb deze data van de RIVM site gedownload. Er kunnen dus ook geen rechten aan worden ontleend. De totalen zullen niet helemaal optellen tot de nationele aantallen omdat er ook gevallen zijn waarvan de woonplaats niet bekend is ten tijde van publicatie. Heb je tips laat maar weten! . . Tip: Bedankt ontwikkelaars van Fastpages (heel handige manier om Jupyter notebooks te bloggen) en Altair (voor de visualisaties). Super om dit eens te proberen. .",
            "url": "https://jvanelteren.github.io/blog/2020/03/23/analyse.html",
            "relUrl": "/2020/03/23/analyse.html",
            "date": " ‚Ä¢ Mar 23, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "Exploring 13M board game reviews",
            "content": "I like playing games, whether it‚Äôs on a computer on as a board game. That‚Äôs why the site boardgamegeek.com is a great resource for inspiration about great games. It has extensive information about games and what people think of them, for example with how many players it‚Äôs best to play and from what age children are ready for it. They also provide an API to interact with the site. I used this to download all the scores that users have given to games. . Using these scores it‚Äôs possible to let the computer identify certain latent factors behind games and users. This technique is called collaborative filtering, and it‚Äôs the same as Netflix uses to recommend what to watch next. Or amazon.com to advise on your next purchase. . In the end what I did was: . Make it into a Kaggle dataset | Did some exploratory data analysis | Got collaborative filtering working | Made it into a webapp, currently offline where people can search for a game and the app will display the games the user probably likes | .",
            "url": "https://jvanelteren.github.io/blog/2019/05/28/boardgames.html",
            "relUrl": "/2019/05/28/boardgames.html",
            "date": " ‚Ä¢ May 28, 2019"
        }
        
    
  
    
        ,"post14": {
            "title": "Wie is de Mol",
            "content": "Wie is de Mol: Ontmaskerd . Wie is de Mol is enorm populair in Nederland. We zijn inmiddels toe aan het 19e seizoen. Dat betekent dat we langzamerhand ook behoorlijk wat data tot onze beschikking krijgen en er data analyse op kunnen loslaten. Het blijkt een hele leuke dataset te zijn en gaandeweg kwamen er veel interessante vragen naar boven. Ik hoop een aantal WidM vragen te beantwoorden en je misschien ook enthousiast te maken voor data science. Als input heb ik informatie van de site gebruikt, die veel informatie bijhoudt. Leuk om ook eens op te kijken. Dank hiervoor Ronald! . En uiteindelijk behandelen we ook de hamvraag, kunnen we het voorspellen: Wie Is De Mol? . Veel leesplezier! . Voor de data-fans, onderaan staat een link naar GitHub om de code in een Jupyter Notebook te downloaden. | Voor de niet data-fans, je kan ook meteen naar beneden scrollen voor de eindconclusies | . Korte uitleg . Voor als je WidM niet kent: het spel start met ongeveer 10 deelnemers. Een van hen is de mol. De deelnemers krijgen opdrachten om geld te verdienen, maar weten dus niet wie de mol is. De mol probeert ervoor te zorgen dat het team weinig geld verdient met de opdrachten. . Elke aflevering is er een stemronde, waarin deelnemers vragen over de mol krijgen. Degene met de meeste fouten moet het spel verlaten. De mol blijft altijd in het spel. Uiteindelijk blijven er nog 3 deelnemers over: de mol en twee deelnemers. De deelnemers krijgen weer vragen over de mol. Degene met het meeste goed is de winnaar. De andere noemen we de verliezer, maar deze is wel ver gekomen! De winnaar verdient de pot. . Kijkcijfers . Even een opwarmertje, en voor AVRO/TROS belangrijk: hoe populair is het programma? In onderstaande grafiek zie je de kijkcijfers van de meest populaire aflevering, per seizoen. Begon het programma nog met 1 miljoen kijkers, inmiddels zitten we aan meer dan 3 miljoen. Dit lijkt momenteel ook het maximum te zijn. . Welke informatie is beschikbaar? . Elke aflevering krijgen we sommige verdenkingen van deelnemers te zien. Als er heel weinig verdenkingen tijdens de aflevering worden gedeeld kunnen we waarschijnlijk niet hele betrouwbare conclusies trekken. We maken een grafiek waarin we berekenen hoeveel procent van de verdenkingen bekend is. 1 betekent dat we alle verdenkingen van alle deelnemers weten. De verdenkingen van de mol nemen we nu nog niet mee, die heeft natuurlijk hele andere motieven om iemand te ‚Äòverdenken‚Äô. . Het lijkt erop dat we als tv kijker iets minder te zien krijgen. Lag tot en met seizoen 9 het percentage nog rond de 80%, tegenwoordig moeten we het met 60% doen. Seizoen 5 en 12 zijn sowieso gekke uitschieters. Dit betekent dat we over deze seizoenen waarschijnlijk niet veel kunnen zeggen. . Hoe verdacht is de mol? . Als deelnemers geen idee hebben wie de mol is zullen ze gokken. Door dit gokgedrag verwachten we dat elk seizoen de mol toevallig een aantal verdenkingen door gokkers op zich krijgt. Het aantal ‚Äògokverdenkingen‚Äô verschilt per seizoen omdat het verschilt hoeveel verdenkingen de tv makers ons laten zien (de grafiek hierboven). . In onderstaande grafiek zie je per seizoen hoeveel ‚Äòstemmen‚Äô de mol heeft gekregen, en hoeveel we hadden verwacht op basis van gokken. Als de gele lijn boven de blauwe lijn komt is de mol verdacht en andersom. . Nico uit seizoen 2 en Margriet uit seizoen 15 zijn behoorlijk verdacht. Maar de meest verdachte mol is toch wel Jon, uit seizoen 9. Zowel Anniek, Dennis als Vivienne hadden hem al vrij snel in de smiezen. . Tegelijkertijd zijn er ook een paar niet verdachte mollen in een seizoen waar er wel veel geld uit de pot is gehaald: seizoen 6 (Milouska), 8 (Dennis) en 17 (Thomas). . Zijn winnaars vaak aan het mollen? . Een veelgehoorde trend is dat er steeds meer gemold wordt door kandidaten die niet de mol zijn. We kunnen dit onderzoeken door te kijken hoe verdacht de winnaar en de verliezer zijn. Terzijde: dit kan natuurlijk ook te maken hebben met hoe verdacht de mol was (verdachte mol = niet verdachte winnaar). . Eens kijken naar de winnaar, in hoeverre hij/zij de aandacht op zich wisten te vestigen. Natuurlijk verwacht je altijd wel een paar verdenkingen op je te krijgen, dus het wordt pas verdacht als je hier boven zit. Het beste voorbeeld hiervan zien we in seizoen 14, waarin Sofie veel meer verdenkingen op zich kreeg dan verwacht. Ook afgelopen seizoen 18 was Ruben een verdachte winnaar. . Toch vind ik het knapper als je kan winnen zonder verdacht te zijn. Bijvoorbeeld seizoen 9 en 12 waarin het heel duidelijk was dat de winnaar een hardwerkende deelnemer was. Complimenten Vivi√´nne en Hadewych! . En verliezers? . Hetzelfde plaatje voor de verliezers. Zoals je hieronder ziet is de verliezer vaak een stuk minder verdacht dan de winnaar: de blauwe lijntjes liggen vaak boven de gele. Ook afgelopen seizoen was Olcay overduidelijk niet de mol. . Uitzondering die de regel bevestigt is seizoen 4, waarin Chandrika zeer verdacht was, maar het uiteindelijk Elise was die echt de mol was. . Kunnen deelnemers de Mol ontmaskeren? . De deelnemers maken elke aflevering een test, waarbij ze vragen over de mol moeten beantwoorden. Soms geven ze ook aan wie ze verdenken. Maar in hoeverre weten de deelnemers wie de mol is, of wordt er maar wat gegokt? Het lijkt logisch dat er op het begin wordt gegokt en dat er uiteindelijk een beter beeld ontstaat wie de mol is. Laten we kijken hoe goed de uiteindelijke winnaar en verliezer weten te voorspellen wie de mol is. . En inderdaad, op het begin van het spel, als er nog veel deelnemers zijn doen de winnaars en verliezers het ongeveer even goed als puur gokken. Dit blijft zo, totdat er nog 4 deelnemers zijn. We zien dat de verliezers het ongeveer even goed blijft doen als gokken, maar de winnaars gaan het veel beter doen. Als er nog 2 deelnemers over zijn (winnaar en verliezer) heeft de winnaar het altijd goed. In de helft van de 18 seizoenen hebben we we hier informatie over. We weten dus niet zeker of het in de andere helft van de seizoenen ook zo was want dat hebben de tv-makers ons niet laten zien. . Maar toch, 100% score: indrukwekkend! . Wie Is De Mol? . Op basis van bovenstaande grafiek zou je zeggen dat het vrij gemakkelijk is om de mol te ontmaskeren: gewoon luisteren naar de winnaar! Alleen, wie de winnaar is dat weten we pas achteraf. Daarom moeten we nu ook de verdenkingen van de mol meenemen in de verdenkingen. Als je naar alle seizoenen kijkt krijgen zowel de mol en de winnaar iets meer verdenkingen dan verwacht. De verliezer is iets minder verdacht. . Onderstaande grafiek geeft aan hoe verdacht de mol winnaar en verliezer waren. Verdachtheid meten we met het aantal verdenkingen die iemand meer heeft gekregen dan je op basis van toeval zou verwachten. We hebben net ook gezien dat de deelnemers pas bij 4 of minder spelers in het spel meer kans hebben om goed te verdenken dan toeval, dus we kijken alleen naar de verdenkingen in de laatste paar rondes. We zien dat over het algemeen de mol het meest verdacht is. . De laatste jaren zien we toch meer molgedrag bij de winnaar en is de winnaar meer verdacht dan de verliezer. In 8 van de 18 seizoenen is de mol degene met het meeste stemmen. . Heel duidelijk is dat de verliezer bijna nooit het meest verdacht is, dit is maar 1 keer voorgekomen (seizoen 3). . In een uiterste poging heb ik nog geprobeerd om het &#39;verdenkingsgedrag&#39; van mol en winnaar te vergelijken. Ook heb ik gekeken naar: . Hoe vaak iemand een tunnelvisie heeft (dezelfde persoon verdenken). Mollen zijn geneigd om 3 of 4 afleveringen dezelfde persoon te verdenken, een soort fake tunnelvisie. | Hoe vaak de verdenkingen van iemand bekend worden gemaakt in de aflevering. Hier kwam geen duidelijk verschil uit tussen mollen en winnaars/verliezers. | Hoe vaak iemand zijn verdenkingen split. De winnaar deed dat iets vaker dan de mol (9 keer mol vaker, 6 keer winnaar vaker, 3 keer gelijk) | Of de mol een man of vrouw was. Het enige nuttige hierbij is wanneer er 2 mannen en 1 vrouw in de finale zitten, de mol meestal een man is (6 van de 7 keer is dit voorgekomen) | . Door een aantal van deze elementen in een statistisch model op te nemen kon ik onderzoeken of de mol te voorspellen is. Dan kijk je dus naar alle verdenkingen en moet je van 3 deelnemers zeggen wie de mol is, bijvoorbeeld vlak voor de finaleaflevering. Uiteindelijk kon ik in 12 van de 18 seizoenen voorspellen wie de mol was, 2/3 kans dus. Toch al een stuk beter dan 1/3 gokkans, maar zeker niet altijd goed. . Money money money . We kunnen ook kijken naar de prijzenpot. In onderstaande grafiek zie je de pot op het einde van het seizoen. De pot lijkt wel steeds kleiner te worden. komt dit doordat er minder geld valt te verdienen, zijn de opdrachten moeilijker of wordt er meer gemold)? . De totale potenti√´le pot was vooral in de eerste seizoenen erg hoog. In seizoen 3 kon er maar lieft 250.000 euro worden verdiend! Daarna het langzaam af. Bezuinigingen bij de publieke omroep? In seizoen 17 en 18 is er weer wat meer te verdienen. . Het percentage van de potenti√´le pot dat wordt binnengehaald schommelt nogal, tussen de 20 en 50 procent. Dit kan natuurlijk door mollen komen, maar soms zijn er ook opdrachten waarbij geld wordt verloren uit de pot. Ik kon geen verband vinden tussen dit percentage en hoe verdacht mol of winnaar was. Misschien komt dit doordat er in sommige seizoenen ook geld kan worden verloren, of misschien is het heel persoonsafhankelijk hoe de mol opereert en hoe goed het team functioneert in geld binnenhalen. . Eigenlijk zijn de winnaar in seizoen 1 (Petra), 2 (Sigrid) en 9 (Hadewych) het meest succesvol geweest. Ze waren ook minder verdacht dan verwacht, dus(?) niet aan het mollen. . De meest succesvolle mol is wat lastiger maar ik neig naar Anne-Marie uit seizoen 12: niet verdacht, wel een kleine pot. Maar seizoen 3, 4, 5 en 7 waren ook prima! . Conclusies . Er zitten grote verschillen tussen de seizoenen in hoe verdacht de mol, de winnaar en de verliezer zijn | De winnaar weet vrijwel altijd wie de mol is, maar weet het pas de laatste paar afleveringen | De verliezer weet meestal niet wie de mol is en had net zo goed kop of munt kunnen gokken | De mol wordt eigenlijk alleen door de winnaar ontmaskerd | De prijzenpot voor WidM is gedaald | We kunnen geen relatie vinden tussen het percentage van de pot die wordt binnengehaald en het mate van verdenking op mol of winnaar | We kunnen op basis van de verdenkingen in de finale iets beter voorspellen wie de mol is (12 van de 18 seizoenen goed voorspeld) | Voor de toekomst kan het leuk zijn om de verdenkingen van het publiek via de mol-app te bekijken. Doen de tv kijkers het beter of wordt er maar wat gegokt en krijgen we eigenlijk te weinig echte hints? | . Welke vragen heb je zelf nog? Veel plezier met Wie is de Mol dit seizoen! . Hier kan je de jupyter notebook downloaden: https://github.com/jvanelteren/wie_is_de_mol . Mocht je data science leuk vinden kan ik je van harte aanraden om eens een gratis online Python programmeercursus te volgen! .",
            "url": "https://jvanelteren.github.io/blog/2019/01/12/WIDM.html",
            "relUrl": "/2019/01/12/WIDM.html",
            "date": " ‚Ä¢ Jan 12, 2019"
        }
        
    
  
    
        ,"post15": {
            "title": "Building a Crypto Trading Bot",
            "content": "What drives you when working on a project? For me motivation is made up of several components: . Curiosity: discover new insights about an interesting topic | Reaching a goal: have a sense of progressing to a goal by solving small obstacles | Learning: grow a skillset and be able to take on larger goals | Challenge &amp; Mastery: overcoming the nagging feeling if I‚Äôll be also to tackle the project | . When I had an idea during the rise of bitcoin these elements where definitely there. But there was another big motivator... . I had made some money with the rise of bitcoin by buying it early and holding on to it. But what would be even better: a constant risk-free return without having to put much effort in. And that was exactly the idea that came to mind. Simple arbitrage: you open an account on multiple crypto exchanges and monitor the prices for different coins. When the prices are drifting apart you take up two positions: buying a coin at exchange A for a low price, and at the same time selling a coin short at exchange B for a high price. Then transferring the coin you‚Äôve bought at exchange A to exchange B to neutralize the position and voila: profit. If I could have a program running on the background this would make me rich! It required a couple of functionalities to program: monitoring the prices though an API, taking up positions, neutralizing these positions and making sure to have enough crypto funds on the buying exchange. The spreads between the exchanged need to outweigh the transaction and transfer costs in order to be profitable. . I experienced how this sense of building a golden goose boosted my motivation to new highs. Sometimes I focus a lot on projects to make progress, but this was really next level üòä. After many hours of coding and learning to interact with crypto API&#39;s, I got everything to work automatically. But alas, the opportunities for risk-free arbitrage became very limited, as a result of the markets maturing. The spreads started to get smaller and smaller making my bot not profitable anymore. . Greed is at the core of many things wrong in this world, but in this case it provided me a very fun and valuable learning experience. .",
            "url": "https://jvanelteren.github.io/blog/2018/03/02/cryptobot.html",
            "relUrl": "/2018/03/02/cryptobot.html",
            "date": " ‚Ä¢ Mar 2, 2018"
        }
        
    
  
    
        ,"post16": {
            "title": "Finding a second hand car bargain",
            "content": "When doing the Udacity Machine Learning Engineer course some years ago I had to come up with a capstone project. Being in the market for a new car, I decided to see if I could predict the price of a second-hand car. This project followed a typical data science workflow: . Coming up with an idea This step if not always mentioned, but it is and extremely important step. If you don‚Äôt come up with an idea you cannot realize it! . | Data gathering I choose gaspedaal.nl as site and scraped about 350.000 cars from it. Scraping itself can be legally sketchy, but since this was an academic project and I didn‚Äôt overload the server I figured it would be ok. Also Gaspedaal.nl is itself a site that scrapes several car marketplaces. . | Data cleaning &amp; preprocessing This step makes sure the data will be of use for a model. It involves removing certain outliers, processing of categorical variables. We all know the garbage in, garbage out principle. . | Model selection The model should generate predictions, but which algorithm to choose. Trying out helps! Choosing some sensible options and pick the best performing one. When you execute a project in a corporate setting of course other deliberations are important such as maintainability, robustness and speed . | Model optimizing Many models have a set of knobs to turn, but what position to put them in for the best results. Again: trying out helps. I‚Äôm still looking for a nice Design of Experiments package to do this, but in this project I used the RandomGridSearch, which basically tries and sees what works. . | Model interpretation People often complain about machine learning being a black box, but when you‚Äôre not dealing with neural nets that statement is incorrect. Visualisation is the easiest step, but there are also packages that open up the black box, such as the shap package. . | . The model worked nicely and I was able to find a reasonably priced Toyota Prius with it. It has two weaknesses though: . The prices on the website are asking prices, not the final selling price. | If the model shows a car is ‚Äòcheap‚Äô, it may be it has other problems (no maintenance? damage?). That‚Äôs why I did test the car at my own garage before making the purchase. | .",
            "url": "https://jvanelteren.github.io/blog/2017/06/29/cars.html",
            "relUrl": "/2017/06/29/cars.html",
            "date": " ‚Ä¢ Jun 29, 2017"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Visit my linkedin profile .",
          "url": "https://jvanelteren.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://jvanelteren.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}