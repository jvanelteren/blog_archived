{
  
    
        "post0": {
            "title": "Turnonderzoek op het journaal",
            "content": ". Op het NOS journaal: 2/3 van turners heeft te maken met grensoverschrijdend gedrag. Als vader met een meisje op turnen krab je je dan toch even achter de oren... Maar, de interesse was gewekt en voor het lidmaatschap op te zeggen ben ik toch even het ruim 400 pagina&#39;s dikke rapport ingedoken. Uiteraard met de databril op. En dan schrik je toch wel, maar vooral van de eenzijdige journalistiek... . Waar komt die 2/3 vandaan? Het journaal meldt dat het gaat om oud-sporters en actieve. Dat klopt niet, het gaat om oud sporters (van voor 2014). Deze konden een vragenlijst invullen op de website van de turnbond. De turnbond beschikte niet over de emailadressen van deze turners, dus de participanten moeten op een andere manier hun weg naar de website hebben moeten vinden. 282 deelnemers hebben de vragenlijst ingevuld. Ter referentie, in 2014 had de turnbond 241.435 leden. De onderzoekers melden zelf ook dat de resultaten niet representatief zijn en dat er geen generaliserende conclusies kunnen worden getrokken over de gehele gymsport. . Er treedt bij dit onderzoek een dubbel selectie-effect op: . Mensen met een sterke mening over het onderwerp zullen de vragenlijst eerder invullen. Vergelijk het met een onderzoek over geluidsoverlast. Welke mensen zullen hierbij reageren, degene die geluidsoverlast ervaren of niet? | 80% van de deelnemers geeft aan aan (semi)topsport te hebben beoefend. Van deze oud-topsporters geeft 85% aan met grensoverschrijdend gedrag te maken te hebben gehad. Bij de semi-topsporters is dit 58% en bij de breedtesporters 35%. Het hoge aandeel van topsporters in de respondenten wordt het gemiddelde omhoog getrokken naar 2/3. Beide effecten werken vertekenend als je een conclusie wilt trekken over de gehele turnsport. De auteurs benoemen het mogelijke selectie-effect. | . Er zijn ook vragenlijsten per email verstuurd, alle (semi) topsporters van na 2014 zijn aangeschreven (8147) en 5% (7136) van de overige leden (180.000). Ongeveer 18% reageerde. Dit is een ietwat magere respons. Hieronder een gedeelte van de infographic van het rapport, deze geeft het verschil weer tussen de ervaringen van topsporters (60-70% te maken met GOG) en recreatieve sporters (15% te maken met GOG). . Het aantal respondenten bij vanuit de recreatieve groep is erg klein, bijvoorbeeld 21 repondenten waren volwassen recreatieve sporters. In werkelijkheid turnt 73% van de turners op recreatief niveau, niet 3% zoals bij de volwassen respondenten. Recreatieve sporters zijn dus enorm ondervertegenwoordigd in de steekproef. Wederom het selectie-effect. De onderzoekers geven aan dat &#39;de omvang van grensoverschrijdend gedrag vrijwel niet betrouwbaar is vast te stellen&#39;. . . Een heel negatief beeld dus op het journaal. Vooral met betrekking tot de breedtesport kan je nauwelijks cijfermatige conclusies trekken, terwijl het wel wordt gepresenteerd als de turnsport als geheel. Het verhaal in het onderzoek ligt genuanceerder, maar dat past natuurlijk niet in het item. . Dan is er ook nog een soort positief nieuws, er wordt onderzoek geciteerd uit 2020, door NOC/NSF gepresenteerd als representatief (n=5.000). Turnen staat bij een vergelijkend onderzoek laag in de middenmoot van sporten waar mensen grensoverschrijdend gedrag hebben meegemaakt (voetbal, handbal, hockey, korfbal scoren veel hoger). Bij seksueel grensoverschrijdend gedrag staat turnen nog lager, ongeveer gelijk met &#39;schaken&#39;. Zie onder de grafiek over emotioneel grensoverschrijdend gedrag uit dat onderzoek. . . Nog meer positief nieuws: van de respondenten geven de volwassenen het turnen gemiddeld een 8 (33% geeft een 9 of 10) en de minderjarigen met een 8,5 (54% geeft een 9 of 10). Deze score ligt bij de topsporters wat lager dan bij de recreanten. Maar komt dat door GOG of doordat topsport als minder leuk wordt ervaren? Het zou interessant zijn om deze getallen nog uit te splitsen in groepen die wel/niet GOG te maken hebben gehad. Dan kan je misschien iets zeggen over de impact van GOG/topsport op turnplezier. Hieronder de grafiek van minderjarige respondenten. . . Dan tenslotte: ik heb echt alleen naar de cijfers gekeken, dit doet niets af aan de ernstige ervaringen die turners in kwestie hebben meegemaakt. Werken aan verbetering van de sport is altijd goed. . Zolang m&#39;n dochter het leuk vindt (en nog geen topsporter is) ga ik in elk geval met gerust hart en veel plezier naar de turntraining! .",
            "url": "https://jvanelteren.github.io/blog/2021/04/29/turnen.html",
            "relUrl": "/2021/04/29/turnen.html",
            "date": " • Apr 29, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Tekst analyse van Tweede Kamer moties",
            "content": ". Nog net voor de verkiezingen deel 2 van het motie-onderzoek! Naast deze blog heb ik ook nog de StemVinder ontwikkeld om snel relevante moties te vinden. . In dit deel kijk ik naar de inhoud van de moties. Op de moties te clusteren naar onderwerp gebruikte ik in eerste instantie een bekende techniek Latent Dirichlet Allocation, maar via een gelukkig toeval kwam ik achter een gloednieuwe aanpak die veel beter werkt! Longhow Lam heeft deze toegepast op kamerdebatten van de Tweede Kamer. . Het Top2Vec algoritme probeert soortgelijke woorden en documenten te clusteren en hieruit onderwerpen te destilleren. In de wordcloud hierboven staan heel generieke woorden die in veel moties voorkomen. Deze zijn niet onderscheidend en worden er automatisch uitgefilterd door het algoritme. Echt weer zo&#39;n voorbeeld van een doorbraak in machine learning die sneller en beter werkt waardoor oude technieken bij het grofvuil kunnen. . Bij de moties worden er ongeveer 250 topics geïdentificeerd. In deze onderwerpen zit wat overlap en het is een beetje lastig visualiseren, dus uiteindelijk heb ik die voor deze blogpost samengevoegd tot 15. Onderop deze blog staan wordclouds van de 15 onderwerpen. . Welk soort onderwerpen staan op de agenda? . Eerst kijken we naar de ontwikkeling van de onderwerpen van de ingediende moties. We weten al dat het absoluut aantal moties stijgt, dus heb ik gekeken naar de relatieve verdeling van de onderwerpen. . Opvallend dat de verhoudingen redelijk stabiel zijn! Je ziet dat in de loop van de tijd klimaat en energie, milieu en regelgeving (heel veel coronaregels zitten hier ook in gecategoriseerd), sociale zaken en wonen omhoog gaan. Omlaag gaan landbouw en dierenwelzijn, natuur en gaswinning, onderwijs en openbaar vervoer. Binnen de onderwerpen zijn natuurlijk wel verschuivingen waar het precies over gaat. We onderzoeken nu de ingediende moties tijdens de afgelopen Tweede Kamer periode. . Meest actieve partijen per onderwerp . We onderzoeken welke partijen het meest actief zijn door op drie manieren naar de data te kijken: . Aantal ingediende moties (per partij per onderwerp) | Aantal succesvolle moties | Aantal succesvolle moties per zetel | In bovenstaande grafiek zien we bijvoorbeeld dat op onderwijs de meeste moties worden ingediend door Groenlinks (1 in de grafiek), gevolgd door de SP (2), PvdA (3) en D66 (4). Een punt van aandacht is dat deze analyse niet aangeeft wat de partijen met de moties willen bereiken, bijvoorbeeld op openbaar vervoer wil VVD waarschijnlijk heel iets anders bereiken dan SP. . PVV is erg actief op justitie, en de PvdD op klimaat, dierenwelzijn milieu en natuur. Ook de enorme output van de SP valt op! Maar ingediend is niet hetzelfde als aangenomen, dat wordt de volgende grafiek: . Wat betreft het aantal succesvolle moties dan zien we daar ineens vier partijen bovendrijven: CDA, D66, GroenLinks en de VVD. Veel regeringspartijen, dat is logisch want die hebben een meerderheid. Ook vind ik het opvallend dat PvdA echt op sociale zaken en het pensioenstelsel succesvol is en GroenLinks op de andere onderwerpen. . Nu kijken we naar het aantal succesvolle moties per zetel . Met je stem koop je op 17 maart politieke invloed. Dit overzicht geeft weer hoeveel &#39;waar je voor je geld&#39; krijgt, hoeveel succesvolle moties een zetel van een partij er doorheen krijgt per onderwerp. Het is weer een heel ander beeld: de christelijke partijen doen het heel erg goed (even gecheckt en inderdaad het Dik-Faber effect bij de ChristenUnie op Zorg, Voordewind op Buitenlandse zaken) en de SP komt een stuk minder terug. Opvallend ook dat D66 relatief weinig scoort op Onderwijs. Partijen die minder in de prijzen vallen zijn FvD (nr 5 op Europese Unie), de PVV nergens en de VVD op financiele sector (nr 5). Bij de VVD is dit te verklaren doordat ze veel zetels bekleedt. . Waar richten de partijen zich op? . In bovenstaande grafieken hebben we de partijen onderling vergeleken. Nu kijken we per partij op welk vlak ze het meest actief zijn . Als een partij een aantal heel grote bollen heeft betekent dit dat de partij zich heel erg richt op dit onderwerp. Zijn er geen grote bollen binnen een partij is de inzet meer over de onderwerpen verspreid. Algemene zaken, Onderwijs en Zorg krijgen bij veel partijen veel aandacht. Daarnaast hebben FvD, PVV, 50PLUS en de PvdD een heel uitgesproken profiel. In het achterliggende notebook heb ik ook nog gekeken naar de ontwikkelingen per partij van de afgelopen 4 kamerperiodes. . Stemgedrag per onderwerp . Dan toch nog eens proberen het stemgedrag te visualiseren. Als de VVD iets indient voor de Financiele Sector betekent dit namelijk iets heel anders dan als de SP dat doet. In onderstaande plots staat per onderwerp het stemgedrag gevisualiseerd. Positief of negatief zegt niets, het gaat om partijen die dichtbij of ver weg van elkaar staan. PvdD en VVD vormen meestal de uitersten en verschillen dus het meeste op stemgedrag. Deze grafieken verklaren meestal zo&#39;n 35%-55% van de variatie in het stemgedrag. Let op: het is dus een versimpeling van de werkelijkheid! . &#39;#&#39; geeft het aantal moties aan en &#39;%&#39; het percentage dat deze visualisatie verklaart. Het meest opvallend is dat FvD en PVV soms in het midden zitten en soms aan de rechterkant. Bij de Europese Unie mengen SP, PvdD en de SGP zich hier ook in. Als het gaat om pensioenen zitten ze juist meer aan de linkerkant. De groep PvdD, SP, GroenLinks, PvdA en DENK zit standaard links, alleen wederom bij de EU en pensioenstelsel wordt gehusseld. 50PLUS zit vaak in het midden, behalve bij pensioenstelsel. . Onderzoek naar klimaat . Omdat ik denk dat klimaat de grootste uitdaging is voor de mensheid heb ik hier de subonderwerpen nog eens doorgenomen. Natuur en milieu zijn natuurlijk ook heel erg belangrijke onderwerpen, maar toch besloten het even bij het klimaat te houden. . De vraag is op welke partij je stemt: PvdD dient enorm veel moties in en bepaalt hier wel het debat mee. Maar D66 en GroenLinks dienen dan weer meer succesvolle moties in. . En hier houdt het een beetje op, voor een stemadvies moet je namelijk uiteindelijk toch weten waar de partijen voor staan. Laat ik daar nu net de StemVinder voor hebben gemaakt. Veel plezier ermee! . . Tip: Bedankt Dimo Angelov, bedenker en ontwikkelaar van Top2Vec, Longhow Lam voor de LinkedIn blogpost en Willem Glasbergen voor de tip! Zonder deze drie was het niet gelukt :-) . Bijlage: classificering van de onderwerpen .",
            "url": "https://jvanelteren.github.io/blog/2021/03/07/kamermoties_topics.html",
            "relUrl": "/2021/03/07/kamermoties_topics.html",
            "date": " • Mar 7, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Data-analyse Tweede Kamer moties",
            "content": ". De verkiezingen komen er weer aan, en de Tweede Kamer heeft een open data portaal. Daar heb ik eens fijn gebruik van gemaakt en alle moties vanaf 2009 gedownload. Het zijn er om precies te zijn 29514 en in dit blog kijk ik of er interessante inzichten uit te halen zijn. . Ontwikkeling van het aantal moties . Het aantal moties stijgt, met name het aantal aangenomen moties. In verkiezingsjaren (2010, 2012 en 2017) ligt het aantal moties duidelijk lager. . Moties die worden aangenomen halen meestal rond de 120 stemmen. Moties die het niet halen blijven meestal rond de 50 stemmen hangen. Eigenlijk zegt zo&#39;n gemiddelde niet zoveel en kan je beter naar de verdeling van het aantal stemmen voor kijken, dat doen we nu met een histogram per kabinetsperiode. . In de histogrammen gaat het vooral om de verdeling van de moties tijdens de kamerperiodes. . Balkenende IV: een piekje van moties die nauwelijks stemmen krijgen (waarschijnlijk protestmoties), een grote piek met moties die rond de 35 stemmen blijven hangen en een piek met unaniem aangenomen moties | Rutte I: relatief veel moties die het nipt wel of juist niet haalden | Rutte II: veel afgewezen moties | Rutte III: hele grote piek in het aantal unaniem aangenomen moties. Dit lijken er ook steeds meer te worden (500 in 2018, 700 in 2019 en 900 in 2020) | . Meestal worden moties ingediend door 1 partij, maar soms zijn er medeindieners. Sinds 2008 is er één special snowflake motie, met maar liefst 16 medeindieners. Kennelijk stond de hele kamer achter een reddingsplan voor VDL Nedcar. . Welke partij is de &#39;tegenpartij&#39;? . Logischerwijs steunt de oppositie de meeste moties, terwijl de regering vaak tegen stemt. De VVD blokkeert de meeste moties. Tijdens Rutte I en II waren deze verschillen nog groter. . Welke partijen dienen het meeste moties in en hoe succesvol zijn ze? . In bovenstaande grafiek zijn de partijen op elkaar gestapeld en is te zien dat het aantal succesvolle moties onder Rutte III sterk is gestegen. De stijging komt vooral door VVD, CDA en Groenlinks. . Deze visualisatie geeft weer hoe succesvol partijen zijn geweest tijdens de verschillende kamerperiodes. Je ziet bijvoorbeeld de PVV, PvdD en SP als partijen met veel moties, maar weinig succesvolle. Ook worden de moties van regeringspartijen vaker aangenomen. Dit komt natuurlijk doordat ze met de regeringspartijen een meerderheid hebben in de TK. Laten we nu eens kijken hoe deze grafiek eruit ziet per zetel, om een &#39;productiviteit&#39; te meten. . Opvallend vind ik het erg lage aantal moties van de VVD per zetel. Het is natuurlijk ook de partij met het hoogste aantal zetels, maar toch. De PvdA is na Rutte II losgegaan, terwijl Groenlinks iets minder indient, maar wel succesvoller is. PvdD dient het meeste moties in per zetel per jaar. Ook SGP en ChistenUnie zijn behoorlijk succesvol per zetel. . Wie zijn de &#39;motiekanonnen&#39; van de Tweede Kamer? . Wie is nu het meest &#39;succesvolle&#39; kamerlid? . De Producent: Lammert van Raan van PvdD dient maar liefst 86 moties in per jaar, hierbij blijft hij Lisa Westerveld van GroenLinks ruim voor (66 per jaar). | De Winnaar: Deze gaat ruimschoots naar Carla Dik-Faber van de ChristenUnie. Zij is met 41 aangenomen moties verreweg het succesvolst. Joba van den Berg-Jansen (CDA) staat op plek twee met 31 successen per jaar, op de voet gevolgd door wederom Lisa Westerveld (30). | De Samenwerker: Kijken we naar de politicus die het meeste moties heeft mede-ingediend staat daar wederom Dik-Faber maar liefst 94 keer als mede-indiener vermeld. In de code heb ik nog volledige top 10 lijstjes per kamerperiode bijgevoegd voor de geinteresseerden. | . Welke partijen werken samen? . Duidelijk is hier te zien dat de regeringspartijen vaak samen moties indienen. Van de oppostiepartijen zijn de PvdA, GroenLinks en de SP vaak mede indiener van elkaars moties. . Au! Dat doet pijn bij FvD! Als we kijken naar het stemgedrag stemmen bijna alle partijen tegen FvD, behalve PVV en Groep Krol. Van de oppositiepartijen krijgen alleen SGP, PvdA en Groenlinks regelmatig steun van de regeringspartijen. . Welke partijen lijken het meeste op elkaar qua stemgedrag? . In bovenstaande grafiek is het stemgedrag van alle partijen platgeslagen op één as met een Principal Component Analaysis. Deze as verklaart 40% van het stemgedrag. Of de bar positief of negatief is maakt niet uit, het gaat erom dat vergelijkbare partijen bij elkaar in de buurt liggen. Kennelijk liggen VVD en PvdD het meest van elkaar verwijderd. . Hieronder visualiseren we het stemgedrag op twee assen. Op deze manier kunnen zo&#39;n 60% van het stemgedrag beschrijven (niet 100%!). Als twee partijen vlak bij elkaar liggen wil dus niet zeggen dat ze altijd hetzelfde stemmen. De horizontale as is groter omdat deze meer van het stemgedrag verklaart. . De x-as lijkt toepasselijk de politieke links-rechts as te beschrijven. De y-as is iets lastiger te duiden, iets met samenwerken vs alleenstaan? Waarschijnlijk komt dit doordat FvD en PVV vaak moties indienen die zij alleen steunen maar de rest van de partijen niet zoals we hebben gezien. . Er zijn grofweg 3 clusters te onderscheiden: . de oppositie linksonder | de regeringspartijen rechtsonder | PVV en FvD bovenaan. | . Ik heb het ook nog met de afgelopen kabinetten vergeleken en komt erop neer dat de ChristenUnie en D66 vaak iets meer naar het midden zitten. In die zin is een &#39;linkse samenwerking&#39; van GroenLinks logischer met SP dan met D66. SGP zit vaak vlakbij de regeringspartijen. . In een volgend blog (dat ik hopelijk nog voor de verkiezingen publiceer) bekijk ik de inhoud van de moties. Kijken of er trends zijn in onderwerpen en welke partij het meest actief is op bepaalde onderwerpen. . . Note: Ik heb enkele visualisaties in de blog achterwege gelaten om het nog enigzins leesbaar te houden. Op Google Colab is deze beschikbaar. De code staat op GitHub (Python) .",
            "url": "https://jvanelteren.github.io/blog/2021/02/20/kamermotiesEDA.html",
            "relUrl": "/2021/02/20/kamermotiesEDA.html",
            "date": " • Feb 20, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Face2Age",
            "content": ". This blog is about predicting someone’s age by their face. I&#39;ve also made an webpage where you can try to beat the computer. . Deep learning has seen incredible results the last couple of year. As long as you have a large enough dataset, it you can transform any input to any output. A couple of examples: . Image classification, where you map an image to a label (input an image of a frog, computer outputs ‘frog’) | Sentence generation (if I start a sentence with ‘Today, the weather is’, computer outputs ‘great, let&#39;s take a walk’. | Recommender system (which is the next video that will be most likely to keep the user watching) As an aside, deep learning is not without it’s ethical problems, for example these social media recommender systems have a tendency to radicalize people, since that maximizes their &#39;engagement&#39; to the platform. | . In this project, I’ve taken on a image regression problem. It’s a nice problem, because the answer is not always obvious: some people look older or younger than they really are. By showing the computer model examples and giving feedback how wrong it is on its prediction, the model is improving. We don’t have to explain anything about how an old or young person looks like. Can you imagine how difficult it would be to program how to recognize wrinkles? This is essentially the wonder of neural networks. . When training a model, an important part is the performance metric. For this task of guessing someone’s age, I’ve chosen Mean Absolute Error, basically how many years you’ve guessed wrong. A prediction of 12 on an actual age of 10 means the MAE is 2, just as a prediction of 8 also has an MAE of 2. . The dataset contains about 10.000 images, I’ve trained the model on 70% of the dataset. That leaves about 3k images which the model has not seen. We use this to test it’s performance. In theory, this performance will generalize to other unseen images. In practice that remains to be seen, since real life images can be much messier, e.g. in quality, zoom level and background. . Below you can see it getting better over time. The horizontal axis displays how many times we feed the training set to the model. The left graph shows performance on the training set, the right graph on the test set. Initially, it’s off by about 11 years, and slowly converging to a MAE of 2 years. But taking the performance on the training dataset is cheating, we are interested in it’s performance on unseen images! The performance there converges to around 4.2. . . Let&#39;s check out predictions on some random images in the test set. In the title the actual age and the predicted age by the model. . That looks pretty good! To take a more general approach, let&#39;s plot the all the images from the test set in a graph. . There are definitely some errors, but overall it seems reasonable. It&#39;s also interesting to plot the faces where the error was largest. . In most of the cases the model was simply off, but there are also faces which look much older or younger, or very blurry ones. Which highlights the importance of understanding the dataset and potentially removing outliers from it. . Another approach is to visualize the average error by age. . The error gets larger as someone gets older, which makes perfect sense: when you see a baby you are not going to guess wrong by more then 5 years, but for someone age 50 that is more difficult. . You could argue for a slight improvement in the predictions with ages &gt; 60, but it could also be an anomaly. There are few really old faces in the dataset, which could be of influence. There are also 300 images of babies age 0 in the dataset, which I removed from the second chart to have a better visualisation. . I’ve build a webpage where you can try out if you can beat the computer, or even upload a selfie for fun to see how old the computer thinks you are. Please take the results with a grain of salt. I’ve taken some selfies and the computer estimated me around 27 to 42, which is ballpark accurate. However, a condolence card of my grandmother age 92 was classified as 62, and although she did look young, 62 was an underestimation. . I’ve had much fun with this project. I hope you like it as well and will try out the application. No guarantees it will be online indefinitely by the way. . . Note: Technical details on how it was build: Pytorch, Pretrained resnet-18 model. Application runs on Google Cloud Platform, with a Nginx and Gunicorn running in Docker container. Python backend in Fastapi. Code available on Github, dataset on Kaggle .",
            "url": "https://jvanelteren.github.io/blog/2020/11/24/face2age.html",
            "relUrl": "/2020/11/24/face2age.html",
            "date": " • Nov 24, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Current preferred data science setup",
            "content": "I’ve spend some time tinkering with getting a preferred data science stack up. In this post I’m detailing the choices made and could also help you get started on GCP. If you just want to start with programming, go to Google Colab and you&#39;re set to go. . . The data science setup is now made up of: . All development in Python (installed via Miniconda), with Pytorch and Fast.ai for deep learning | A personal computer with Windows 10, VSCode with Jupyter notebooks functionality | Google Cloud Platform with a Docker container running Linux Ubuntu | Github for storing the codebase and a github action based blog running fastpages | . For me this works best at the moment. Some remarks on tradeoffs. . Python vs other languages. Python is todays language of choice for data science. It&#39;s just so simple to express ideas in code. Also there are just so many packages available with useful functionality that the whole world is basically an import statement away. Maybe I’ll learn Julia, Kotlin or Swift once, but for now I’m set. . | Pytorch vs TensorFlow: Pytorch is so much easier compared to Tensorflow. I remember doing an introduction on Tensorflow and I found it difficult to grasp. . | Pytorch vs Fast.ai. Fast.ai is kind of the Keras of Pytorch. It has been a blessing and I do highly recommend it. The online course is great. Also you can get a deeplearning model running in no time. But it’s also an extra layer of abstraction to remember on top of trying to learn Pytorch. So right now I’m now mostly using with Pytorch and Fast.ai once in a while. . | Windows vs Linux: OK for data science everyone says Linux is the go to, but I’m just so accustomed to Windows! I can definitely see the advantages of Linux and are slowly gravitating towards using a command line interface more. Windows made a big step with WSL2, so you can now run Linux from within Windows easily, so I did install Ubuntu locally. Maybe in the future I’ll switch fully to Linux, but for now this is working fine. . | VSCode vs Jupyter Notebooks. In my opinion the setup of running notebooks within VSCode combines the advantages of a fully fledged IDE with the agile development that notebooks are known for. . | Having an own computer vs doing everything in the cloud. Working in the cloud always has a startup of a couple of minutes. My time is limited, so I do prefer to open VSCode and start coding right away. When I need more compute I use the cloud. . | GCP vs other cloud platforms. This decision was taken based on the $300 free credit you get with GCP. . | Github: Initially I had all the code on my local computer and I used Git for version control. Now that I sometimes iterate between working locally and in the cloud, I store the main branch on Github and push/pull from whichever environment I’m working on. . | Fastpages: First I started on Medium, but fastpages is a live saver for publishing from notebooks. It makes it actually fun to blog, instead of a chore duplicating your work in a blog article . | Docker: For reproducibility, Docker is king. For cloud computing I think it’s the best way. You just make a Dockerfile and know what you will get. Also it can make the steps to deployment easier. . | App deployment: Don’t know what the best is yet. Have tried Render, and could get a webserver it to work with GCP as well. You can even deploy on Binder with a notebook. Guess this one depends on the use case. . | . The remainer of the post is dedicated to helping you out with setting up GCP with Docker. Some things you need: . The CLI command from Windows to get a VM running | A startup script to make sure the VM runs the container | A Dockerfile to build a docker image from | . Let&#39;s start with the CLI command . gcloud beta compute instances create gpu ` --zone=us-central1-c ` --machine-type=n1-standard-8 ` --subnet=default ` --service-account=YOURSERVICEACCOUNT-compute@developer.gserviceaccount.com ` --image-family=common-cu110 ` --image-project=deeplearning-platform-release ` --boot-disk-size=50GB ` --scopes=https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/devstorage.full_control ` --accelerator=type=nvidia-tesla-k80,count=1 ` --metadata=install-nvidia-driver=True ` --maintenance-policy=TERMINATE ` --metadata-from-file startup-script=startup-gpu.sh ` --preemptible . You can create a GCP VM from the command line interface (CLI) or through the browser based console. Play around with the console to get an idea. Then, on the bottom click gcloud command to see the CLI command to copy in your terminal . This command uses ` at end of line since it&#39;s run from Windows Powershell. If you use Linux, use backslash . Don&#39;t use Container Optimizer OS, as of november 2020 they dont install nvidia container runtime, meaning it&#39;s difficult to make use of the GPU inside the container. An approach that works is to use a data science image like common-cu110 as I&#39;ve used here. . The K80 is the cheapest GPU, good for experimenting. . Also, use --preemtible. You&#39;re VM may be stopped unexpectedly, but it&#39;s about 66% cheaper! . Next up is the startup script... . # first some waiting until gpu drivers are truly installed while ! [[ -x &quot;$(command -v nvidia-smi)&quot; ]]; do echo &quot;sleep to check&quot; sleep 5s done echo &quot;nvidia-smi is installed&quot; while [[ $(command nvidia-smi| cut -c1-10) == &quot;NVIDIA-SMI&quot;* ]]; do echo &quot;$(command nvidia-smi)&quot; echo &quot;sleeping to check&quot; sleep 5s done echo &quot;$(command nvidia-smi)&quot; echo &quot;nvidia-smi drivers are up&quot; # if you have a persistent disk you can use this to automatically mount it, otherwise remove it if [ ! -d &quot;/mnt/disks/storage&quot; ] then sudo mkdir -p /mnt/disks/storage sudo mount -o discard,defaults /dev/sdb /mnt/disks/storage sudo chmod a+w /mnt/disks/storage sudo cp /etc/fstab /etc/fstab.backup sudo blkid /dev/sdb echo UUID=`sudo blkid -s UUID -o value /dev/sdb` /mnt/disks/storage ext4 discard,defaults,nofail 0 2 | sudo tee -a /etc/fstab echo &quot;mounting complete &quot; else echo &quot;not first startup&quot; fi # startup your Docker container, with port 6006 mapped to Docker for Tensorboard gcloud auth configure-docker docker run -d -p 0.0.0.0:6006:6006 --gpus all --ipc=&quot;host&quot; -v /mnt/disks/storage:/ds gcr.io/delta-deck-285906/dockerfile echo &#39;Docker run with GPUs&#39; . The first part of the startup script is mainly to wait until the gpu drivers are properly installed. Otherwise, docker run --gpus all will throw an error. Additionally, I like to use a persistent disk. To avoid the hassle of having to mount it every time I startup a new VM, this script does the work for you. Finally the most important is the Docker run instruction. It opens your container with GPU support. The first time you start up your VM it will take some minutes, but afterwards it&#39;s almost immediate. . After this I like to connect to the running container with Vscode Remote-Container Attach to running container command. Checkout the Vscode docs for how to set this up. Basically you need to put the external ip of the VM into your SSH config file and add a line to your settings.json . &quot;docker.host&quot;: &quot;ssh://YOURUSER@xxx.xxx.xxx.xxx&quot;, . Host xxx.xxx.xxx.xxx HostName xxx.xxx.xxx.xxx.xxx IdentityFile localpath/to/publicsshkey User YOURUSER StrictHostKeyChecking no . One final file to share: the Dockerfile which you can use to build your Docker image . FROM nvidia/cuda:10.2-runtime-ubuntu18.04 ##Set environment variables ENV LANG=C.UTF-8 LC_ALL=C.UTF-8 RUN apt-get update --fix-missing &amp;&amp; apt-get install -y wget byobu curl git-core python3-virtualenv unzip &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/* RUN wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-py38_4.8.3-Linux-x86_64.sh -O ~/miniconda.sh &amp;&amp; /bin/bash ~/miniconda.sh -b -p /opt/conda &amp;&amp; rm ~/miniconda.sh &amp;&amp; ln -s /opt/conda/etc/profile.d/conda.sh /etc/profile.d/conda.sh &amp;&amp; echo &quot;. /opt/conda/etc/profile.d/conda.sh&quot; &gt;&gt; ~/.bashrc &amp;&amp; echo &quot;conda activate base&quot; &gt;&gt; ~/.bashrc ENV PATH /opt/conda/bin:$PATH RUN pip --no-cache-dir install --upgrade altair ipykernel kaggle fastbook tensorboard diskcache &amp;&amp; conda install -c fastai -c pytorch fastai &amp;&amp; pip uninstall -y pillow &amp;&amp; pip install pillow-simd --upgrade &amp;&amp; mkdir -p ds/.kaggle &amp;&amp; git clone https://github.com/fastai/fastbook.git /ds/fastbook # Open Ports for Jupyter # EXPOSE 7745 #Setup File System ENV HOME=/ds ENV SHELL=/bin/bash ENV KAGGLE_CONFIG_DIR=/ds/.kaggle VOLUME /ds WORKDIR /ds # Make sure the container stays open CMD tail -f /dev/null . The Docker tutorial by Hamel Husain has helped me greatly, especially the advice to use someone elses dockerfile and start making it your own by gradually adapting. The above dockerfile is based upon his actually. . That&#39;s it, hope it has helped you! .",
            "url": "https://jvanelteren.github.io/blog/2020/10/31/data_science_setup.html",
            "relUrl": "/2020/10/31/data_science_setup.html",
            "date": " • Oct 31, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Red-Black trees",
            "content": "After playing around with red-black trees for some time, I’ve grown to really like them, but also hate them at the same time! I&#39;ll explain in this blog why. To understand what a red-black tree is, we’ll first have to touch upon the concept of a binary search tree. The binary search tree is a method of ordering items that can be compared to each other. The easiest example is of course numbers (1 &lt; 2), other object such as letters (a &lt; b) or words (short &lt; longerword) can also be compared. . A binary tree is very simple and I had fun making one with my six year old daughter. She came up with a list of numbers and together we added them to the tree. The root of the tree is the first item you start with. Next, to add another item you simply check if the item is smaller or larger than the root. If it’s smaller it gets stored into the left branch, if it’s larger it goes to the right branch. A node in the tree can have only one branch on each side. Therefore the tree will have to get deeper when more nodes are added. As an example, a tree with 3 layers holds a maximum of 1+2+4 = 7 nodes. Below an example, where it takes three steps to reach 5,14 and 55 and four steps to reach 62 and 66. These nodes are the edge of the tree and are called leaves. . The advantage of binary search trees is that the items are ordered. For example, you can easily lookup the minimum (just always go left from the root). But also finding an item can be very quick, which is expressed by the number of steps from the root. It makes sense, if you are interested in the left side of the tree, you no longer need to search the right side. . But think about a scenario where you insert numbers in order, ascending. The tree would only have right branches! This effectively means you are just storing a list. Now for a small tree (as the one below), that is no problem, but if you are storing a million items this way, you would have to search a million items before inserting the next number. If the tree would have been balanced, it would only take about 20 steps from the root to any leaf (1 million log base 2). . This is where red-black trees come in. They are self-balancing to solve the above problem. In a red-black tree, items are colored in two colors. You’ve guessed it, red or black. There are a couple of rules: . The root is always black | While going from root to any leaf, you’ll never pass two consecutive red items | The amount of black items you pass while going to an end of the tree is the same for each leaf of the tree. | . To preserve these properties insertion and removal can require certain operations, such as recoloring certain items, or rotating part of the tree. And this is where my love and hate comes in. It’s awesome to see the different shapes the tree can take while balancing. Even the root of the tree can change in the process. A couple of examples: . In the above figure, numbers 0 to 10 were inserted in order. The graph shows that the redblack tree has been rotated to now have 3 as root (no longer the 0 it started with initially). Also the paths from the root (3) to the leaves (0,2,4,6,8 and 9) all cross exactly 3 black nodes! . If we insert 50 items in order, a nice balanced tree appears . to_insert = list(range(50)) RBTree(to_insert,silent=True).draw() . When we randomize the insertion order a completely different tree arises, but still it&#39;s nicely balanced. . random.shuffle(to_insert) RBTree(to_insert,silent=True).draw() . I think this looks elegant. However, it’s known that redblack trees can be difficult to implement and indeed it&#39;s been an absolute pain to code the algorithms, with some difficult debugging to take care of all the edge cases to make sure the code runs correctly. More detailes of all the cases you can encounter at Wikipedia. I’ve gained new appreciation for programming concepts such as unit testing, refactoring, and plain old careful reading of the specification. Seeing it work has made this project worth it! . After some reading, I’ve also come across the treap (tree-heap), which is basically using random numbers to make the tree structure as if the items would have been inserted in random order. Which will make the tree balanced with a high probablility. . To illustrate the randomness, I&#39;ve twice made a treap with 50 items inserted in order. The resulting trees are different, which does not happen with red-black trees when the insertion order is the same. Treaps look much different then the red-black trees as well. . Treaps are much simpler to implement and outperform red-black trees on insertion, search and deletion, but due to their randomized nature are less consistent. Also red-black trees look nicer in my opinion. . That&#39;s it, hope you enjoyed it this exploration of trees! . . Tip: This page has a nice animation how red-black trees are build. Additionally, Wikipedia has more information about binary search trees, red black trees and treaps .",
            "url": "https://jvanelteren.github.io/blog/2020/09/12/redblacktree.html",
            "relUrl": "/2020/09/12/redblacktree.html",
            "date": " • Sep 12, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Predicting the value of a house",
            "content": "Recently I’ve made my way into Kaggle. If it’s new for you, I highly recommend checking it out. Kaggle is a platform where organizations host data science competitions. They come up with a data science challenge, make the data available to Kaggle users, and many data scientist worldwide compete to get the highest score on the leaderboard. After a defined period the competition ends and the winner is awarded with a (monetary) price. . Participants also share their code (kernels), and have discussions on the data. This makes it an excellent platform to learn. The competitions can be a bit intimidating, since it can have extremely large datasets (100GB upwards), the objectives can be challenging (imaging, audio, text, combinations) and figuring out how to submit is not always trivial. But of course you can start with simpler competitions such as the classic Titanic example. . Since I’m quite familiar with tabular data I decided to give the housing competition a try. The training data consists of many features describing about 1500 houses and their selling price. After numerous experiments I ended up with a top 3% score on the leaderboard before throwing in the proverbial towel. The rush of inching up the leaderboard made it a great experience! . Afterwards I wrote about the main insights, learnings and questions . Next up: probably a imaging competition with Pytorch or fast.ai .",
            "url": "https://jvanelteren.github.io/blog/2020/07/26/housing.html",
            "relUrl": "/2020/07/26/housing.html",
            "date": " • Jul 26, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Exploring flight patterns above The Netherlands",
            "content": "Some years ago I woke up early because of a loud aircraft flying over. Couldn’t get back to sleep and decided to use these precious early hours to visualize the air traffic around Hilversum. . Every aircraft is equipped with a device called a transponder that transmits flight data about the flight into the air. Organizations like OpenSky aggregate these data and make them available. Below a screenshot of the result, you can see the tracks and some information about the flight is displayed. . . But when revisiting this initial project, I felt there were more opportunities. I obtained air traffic above the Netherlands from February to April (monday&#39;s only), resulting in 11 full days of traffic. Below a first visualisation. . When reading this post on a computer, I recommend zooming in with ctrl + mousewheel. On mobile it&#39;s with your fingers :) Use the buttons on the right to zoom in on the map. If you see a bright white line over your hometown, there is probably a lot of air traffic flying over. . Panel . . Let&#39;s see if there are more interesting patterns and visualisations. First we split the traffic by altitude. . Start or landing | Departure/arrival | Aircraft passing | . Red: The lowest flying traffic. Airfields such as Eelde, Eindhoven, Dusseldorf and Brussels are visible. | Blue: All the complex movements of traffic in and out of Amsterdam. These are standard routes being flown to keep the traffic manageable, so called STARs and SIDs. | Green: The highest flying aircraft are passing over in mostly straight tracks. | . There are more properties in the data, such as altitude, vertical speed and velocity. . Vertical rate (red=desc) | Mean altitude per 1000m | Mean velocity, dark=slow | . Left: all the arriving flights are red and departures are blue. | Middle: This disco shows aircraft climbing or descending. The colormap is increasing with 1000m per color, starting from red for 0-1000m. Compare it with the left graph: departing flights are quickly climbing to purple, whereas arrivals are flying lower longer. The green to yellow transitions indicate the points where arrival flights are converging for their approach. | Right: the average speed of the aircraft. Also here you see arrival routes are darker (slower) than departures. | . And because COVID-19 is here, let&#39;s plot the data of the past weeks. . 2020-03-09 | 2020-03-16 | 2020-03-23 | 2020-03-30 | 2020-04-06 | 2020-04-13 | . &#39;Normally&#39; there are 2700 flights above the Netherlands (including some North Sea) with a total airtime of 840 hours per day. That is the equivalent of about 35 aircraft flying continuously. The graph shows the dramatic slowdown to about 1/8 of the original volume. . The firelike image on the left side is slowly turning into a collection of night flies: the slowdown of traffic can be easily seen. This has been analyzed more extensively here. . I also went through callsigns that occur most often. Grouping different types of traffic results in some interesting patterns. A small quiz: which pattern belongs to: . The coastguard | Aerial photography | Military flights | Emergency care flights (trauma) | Police helicopters | Commercial helicopter flights | . Answers on the bottom of the post. . A | B | C | . D | E | F | . Let&#39;s end with some visualisations with a certain shade of blue. What type of flights do they represent? . | | | . That&#39;s it, I had fun visualizing all of this, hope you enjoyed reading it! . Answers to the above: . A = Police helicopters. Lots of hovering probably. To the east the German police helicopters, with callsign HUMMEL. | B = Commercial helicopter flights. They mostly start from airfied Den Helder, flying personell to offshore rigs | C = Emergency medical flights. With callsign LIFELN (lifeliner), these helicopters are stationed in Amsterdam, Groningen, Rotterdam and Eindhoven. | D = Aerial photography. To capture the landscape below, these flights often have dense tracks flying back and forth. | E = Coast Guard, with callsign NCG | F = Military. In april a Boeing E-3 Sentry departed from NATO Air Base Geilenkirchen with probably a surveillance training mission. | . And the blues represent our flagship carrier KLM! If you want you can download the higher resolution images . . Tip: Thanks to OpenSky, Datashader and some wonderful tutorials on the internet, e.g. US Census and PyViz. I used code from these examples as well. . . Note: Here you can find my other posts .",
            "url": "https://jvanelteren.github.io/blog/2020/04/22/flights_above_nl.html",
            "relUrl": "/2020/04/22/flights_above_nl.html",
            "date": " • Apr 22, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Ontwikkeling positieve COVID19 testuitslagen",
            "content": "Update 31 maart: Het RIVM is overgegaan op een ander type data, namelijk het aantal ziekenhuisopnames per gemeente, alleen zonder historie te publiceren. Hiermee komt er een einde aan deze visualisatie. Misschien ga ik de ziekenhuisopnames nog een keer visualiseren. . Update 18 april: uiteindelijk is de beste informatie de oversterfte per week. Deze is te vinden op de site van het CBS . Dagelijks publiceert het RIVM de inmiddels welbekende testkaart met daarop het aantal mensen dat per 100.000 inwoners in de gemeente positief is getest op Covid-19. Het leek me interessant om het verloop per gemeente te visualiseren. . Hieronder zie je drie grafieken: . Aantal: Totaal aantal positieve testcases (cumulatief) | Relatief: Totaal aantal positieve testcases per 100.000 inwoners | Groei: Toename van het aantal gevallen ten opzichte van 4 dagen geleden. Factor 0 betekent geen extra gevallen, factor 1 betekent een verdubbeling en factor 2 betekent dat er 2x zoveel cases bij zijn gekomen als dat er 4 dagen geleden waren (een verdrievoudiging van het totaal aantal gevallen). | . Je kan met de slider het verloop van de epidemie volgen. Zoom in als je hem moeilijk te pakken krijgt. Dag 0 is 3 maart, dit was de eerste dag waarvan ik data kon terug vinden op de site van het RIVM. De laatste dag is 30 maart. . Tenslotte nog een mogelijkheid om het verloop in een specifieke gemeente te bekijken . . Important: Omdat in Nederland lang niet alle gevallen worden getest ligt het werkelijke aantal cases waarschijnlijk veel hoger. Weinig cases in jouw gemeente wil niet zeggen dat er niet meer gevallen zijn! Ook zal bijvoorbeeld een ziekenhuis in de gemeente de aantallen beinvloeden vanwege relatief vaker geteste zorgmedewerkers. Pas als er in Nederland veel meer gaat wordt getest kan je er echt conclusies aan verbinden. Landelijk zeggen IC opnames momenteel meer. . . Warning: Je ziet dat sommige lijntjes heel erg stijl omhoog gaan, dat moeten we proberen te verminderen. Houdt je dus aan de maatregelen en adviezen. . . Note: Ik ben geen specialist en heb deze data van de RIVM site gedownload. Er kunnen dus ook geen rechten aan worden ontleend. De totalen zullen niet helemaal optellen tot de nationele aantallen omdat er ook gevallen zijn waarvan de woonplaats niet bekend is ten tijde van publicatie. Heb je tips laat maar weten! . . Tip: Bedankt ontwikkelaars van Fastpages (heel handige manier om Jupyter notebooks te bloggen) en Altair (voor de visualisaties). Super om dit eens te proberen. .",
            "url": "https://jvanelteren.github.io/blog/2020/03/23/analyse.html",
            "relUrl": "/2020/03/23/analyse.html",
            "date": " • Mar 23, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Exploring 13M board game reviews",
            "content": "I like playing games, whether it’s on a computer on as a board game. That’s why the site boardgamegeek.com is a great resource for inspiration about great games. It has extensive information about games and what people think of them, for example with how many players it’s best to play and from what age children are ready for it. They also provide an API to interact with the site. I used this to download all the scores that users have given to games. . Using these scores it’s possible to let the computer identify certain latent factors behind games and users. This technique is called collaborative filtering, and it’s the same as Netflix uses to recommend what to watch next. Or amazon.com to advise on your next purchase. . In the end what I did was: . Make it into a Kaggle dataset | Did some exploratory data analysis | Got collaborative filtering working | Made it into a webapp, currently offline where people can search for a game and the app will display the games the user probably likes | .",
            "url": "https://jvanelteren.github.io/blog/2019/05/28/boardgames.html",
            "relUrl": "/2019/05/28/boardgames.html",
            "date": " • May 28, 2019"
        }
        
    
  
    
        ,"post10": {
            "title": "Wie is de Mol",
            "content": "Wie is de Mol: Ontmaskerd . Wie is de Mol is enorm populair in Nederland. We zijn inmiddels toe aan het 19e seizoen. Dat betekent dat we langzamerhand ook behoorlijk wat data tot onze beschikking krijgen en er data analyse op kunnen loslaten. Het blijkt een hele leuke dataset te zijn en gaandeweg kwamen er veel interessante vragen naar boven. Ik hoop een aantal WidM vragen te beantwoorden en je misschien ook enthousiast te maken voor data science. Als input heb ik informatie van de site gebruikt, die veel informatie bijhoudt. Leuk om ook eens op te kijken. Dank hiervoor Ronald! . En uiteindelijk behandelen we ook de hamvraag, kunnen we het voorspellen: Wie Is De Mol? . Veel leesplezier! . Voor de data-fans, onderaan staat een link naar GitHub om de code in een Jupyter Notebook te downloaden. | Voor de niet data-fans, je kan ook meteen naar beneden scrollen voor de eindconclusies | . Korte uitleg . Voor als je WidM niet kent: het spel start met ongeveer 10 deelnemers. Een van hen is de mol. De deelnemers krijgen opdrachten om geld te verdienen, maar weten dus niet wie de mol is. De mol probeert ervoor te zorgen dat het team weinig geld verdient met de opdrachten. . Elke aflevering is er een stemronde, waarin deelnemers vragen over de mol krijgen. Degene met de meeste fouten moet het spel verlaten. De mol blijft altijd in het spel. Uiteindelijk blijven er nog 3 deelnemers over: de mol en twee deelnemers. De deelnemers krijgen weer vragen over de mol. Degene met het meeste goed is de winnaar. De andere noemen we de verliezer, maar deze is wel ver gekomen! De winnaar verdient de pot. . Kijkcijfers . Even een opwarmertje, en voor AVRO/TROS belangrijk: hoe populair is het programma? In onderstaande grafiek zie je de kijkcijfers van de meest populaire aflevering, per seizoen. Begon het programma nog met 1 miljoen kijkers, inmiddels zitten we aan meer dan 3 miljoen. Dit lijkt momenteel ook het maximum te zijn. . Welke informatie is beschikbaar? . Elke aflevering krijgen we sommige verdenkingen van deelnemers te zien. Als er heel weinig verdenkingen tijdens de aflevering worden gedeeld kunnen we waarschijnlijk niet hele betrouwbare conclusies trekken. We maken een grafiek waarin we berekenen hoeveel procent van de verdenkingen bekend is. 1 betekent dat we alle verdenkingen van alle deelnemers weten. De verdenkingen van de mol nemen we nu nog niet mee, die heeft natuurlijk hele andere motieven om iemand te ‘verdenken’. . Het lijkt erop dat we als tv kijker iets minder te zien krijgen. Lag tot en met seizoen 9 het percentage nog rond de 80%, tegenwoordig moeten we het met 60% doen. Seizoen 5 en 12 zijn sowieso gekke uitschieters. Dit betekent dat we over deze seizoenen waarschijnlijk niet veel kunnen zeggen. . Hoe verdacht is de mol? . Als deelnemers geen idee hebben wie de mol is zullen ze gokken. Door dit gokgedrag verwachten we dat elk seizoen de mol toevallig een aantal verdenkingen door gokkers op zich krijgt. Het aantal ‘gokverdenkingen’ verschilt per seizoen omdat het verschilt hoeveel verdenkingen de tv makers ons laten zien (de grafiek hierboven). . In onderstaande grafiek zie je per seizoen hoeveel ‘stemmen’ de mol heeft gekregen, en hoeveel we hadden verwacht op basis van gokken. Als de gele lijn boven de blauwe lijn komt is de mol verdacht en andersom. . Nico uit seizoen 2 en Margriet uit seizoen 15 zijn behoorlijk verdacht. Maar de meest verdachte mol is toch wel Jon, uit seizoen 9. Zowel Anniek, Dennis als Vivienne hadden hem al vrij snel in de smiezen. . Tegelijkertijd zijn er ook een paar niet verdachte mollen in een seizoen waar er wel veel geld uit de pot is gehaald: seizoen 6 (Milouska), 8 (Dennis) en 17 (Thomas). . Zijn winnaars vaak aan het mollen? . Een veelgehoorde trend is dat er steeds meer gemold wordt door kandidaten die niet de mol zijn. We kunnen dit onderzoeken door te kijken hoe verdacht de winnaar en de verliezer zijn. Terzijde: dit kan natuurlijk ook te maken hebben met hoe verdacht de mol was (verdachte mol = niet verdachte winnaar). . Eens kijken naar de winnaar, in hoeverre hij/zij de aandacht op zich wisten te vestigen. Natuurlijk verwacht je altijd wel een paar verdenkingen op je te krijgen, dus het wordt pas verdacht als je hier boven zit. Het beste voorbeeld hiervan zien we in seizoen 14, waarin Sofie veel meer verdenkingen op zich kreeg dan verwacht. Ook afgelopen seizoen 18 was Ruben een verdachte winnaar. . Toch vind ik het knapper als je kan winnen zonder verdacht te zijn. Bijvoorbeeld seizoen 9 en 12 waarin het heel duidelijk was dat de winnaar een hardwerkende deelnemer was. Complimenten Viviënne en Hadewych! . En verliezers? . Hetzelfde plaatje voor de verliezers. Zoals je hieronder ziet is de verliezer vaak een stuk minder verdacht dan de winnaar: de blauwe lijntjes liggen vaak boven de gele. Ook afgelopen seizoen was Olcay overduidelijk niet de mol. . Uitzondering die de regel bevestigt is seizoen 4, waarin Chandrika zeer verdacht was, maar het uiteindelijk Elise was die echt de mol was. . Kunnen deelnemers de Mol ontmaskeren? . De deelnemers maken elke aflevering een test, waarbij ze vragen over de mol moeten beantwoorden. Soms geven ze ook aan wie ze verdenken. Maar in hoeverre weten de deelnemers wie de mol is, of wordt er maar wat gegokt? Het lijkt logisch dat er op het begin wordt gegokt en dat er uiteindelijk een beter beeld ontstaat wie de mol is. Laten we kijken hoe goed de uiteindelijke winnaar en verliezer weten te voorspellen wie de mol is. . En inderdaad, op het begin van het spel, als er nog veel deelnemers zijn doen de winnaars en verliezers het ongeveer even goed als puur gokken. Dit blijft zo, totdat er nog 4 deelnemers zijn. We zien dat de verliezers het ongeveer even goed blijft doen als gokken, maar de winnaars gaan het veel beter doen. Als er nog 2 deelnemers over zijn (winnaar en verliezer) heeft de winnaar het altijd goed. In de helft van de 18 seizoenen hebben we we hier informatie over. We weten dus niet zeker of het in de andere helft van de seizoenen ook zo was want dat hebben de tv-makers ons niet laten zien. . Maar toch, 100% score: indrukwekkend! . Wie Is De Mol? . Op basis van bovenstaande grafiek zou je zeggen dat het vrij gemakkelijk is om de mol te ontmaskeren: gewoon luisteren naar de winnaar! Alleen, wie de winnaar is dat weten we pas achteraf. Daarom moeten we nu ook de verdenkingen van de mol meenemen in de verdenkingen. Als je naar alle seizoenen kijkt krijgen zowel de mol en de winnaar iets meer verdenkingen dan verwacht. De verliezer is iets minder verdacht. . Onderstaande grafiek geeft aan hoe verdacht de mol winnaar en verliezer waren. Verdachtheid meten we met het aantal verdenkingen die iemand meer heeft gekregen dan je op basis van toeval zou verwachten. We hebben net ook gezien dat de deelnemers pas bij 4 of minder spelers in het spel meer kans hebben om goed te verdenken dan toeval, dus we kijken alleen naar de verdenkingen in de laatste paar rondes. We zien dat over het algemeen de mol het meest verdacht is. . De laatste jaren zien we toch meer molgedrag bij de winnaar en is de winnaar meer verdacht dan de verliezer. In 8 van de 18 seizoenen is de mol degene met het meeste stemmen. . Heel duidelijk is dat de verliezer bijna nooit het meest verdacht is, dit is maar 1 keer voorgekomen (seizoen 3). . In een uiterste poging heb ik nog geprobeerd om het &#39;verdenkingsgedrag&#39; van mol en winnaar te vergelijken. Ook heb ik gekeken naar: . Hoe vaak iemand een tunnelvisie heeft (dezelfde persoon verdenken). Mollen zijn geneigd om 3 of 4 afleveringen dezelfde persoon te verdenken, een soort fake tunnelvisie. | Hoe vaak de verdenkingen van iemand bekend worden gemaakt in de aflevering. Hier kwam geen duidelijk verschil uit tussen mollen en winnaars/verliezers. | Hoe vaak iemand zijn verdenkingen split. De winnaar deed dat iets vaker dan de mol (9 keer mol vaker, 6 keer winnaar vaker, 3 keer gelijk) | Of de mol een man of vrouw was. Het enige nuttige hierbij is wanneer er 2 mannen en 1 vrouw in de finale zitten, de mol meestal een man is (6 van de 7 keer is dit voorgekomen) | . Door een aantal van deze elementen in een statistisch model op te nemen kon ik onderzoeken of de mol te voorspellen is. Dan kijk je dus naar alle verdenkingen en moet je van 3 deelnemers zeggen wie de mol is, bijvoorbeeld vlak voor de finaleaflevering. Uiteindelijk kon ik in 12 van de 18 seizoenen voorspellen wie de mol was, 2/3 kans dus. Toch al een stuk beter dan 1/3 gokkans, maar zeker niet altijd goed. . Money money money . We kunnen ook kijken naar de prijzenpot. In onderstaande grafiek zie je de pot op het einde van het seizoen. De pot lijkt wel steeds kleiner te worden. komt dit doordat er minder geld valt te verdienen, zijn de opdrachten moeilijker of wordt er meer gemold)? . De totale potentiële pot was vooral in de eerste seizoenen erg hoog. In seizoen 3 kon er maar lieft 250.000 euro worden verdiend! Daarna het langzaam af. Bezuinigingen bij de publieke omroep? In seizoen 17 en 18 is er weer wat meer te verdienen. . Het percentage van de potentiële pot dat wordt binnengehaald schommelt nogal, tussen de 20 en 50 procent. Dit kan natuurlijk door mollen komen, maar soms zijn er ook opdrachten waarbij geld wordt verloren uit de pot. Ik kon geen verband vinden tussen dit percentage en hoe verdacht mol of winnaar was. Misschien komt dit doordat er in sommige seizoenen ook geld kan worden verloren, of misschien is het heel persoonsafhankelijk hoe de mol opereert en hoe goed het team functioneert in geld binnenhalen. . Eigenlijk zijn de winnaar in seizoen 1 (Petra), 2 (Sigrid) en 9 (Hadewych) het meest succesvol geweest. Ze waren ook minder verdacht dan verwacht, dus(?) niet aan het mollen. . De meest succesvolle mol is wat lastiger maar ik neig naar Anne-Marie uit seizoen 12: niet verdacht, wel een kleine pot. Maar seizoen 3, 4, 5 en 7 waren ook prima! . Conclusies . Er zitten grote verschillen tussen de seizoenen in hoe verdacht de mol, de winnaar en de verliezer zijn | De winnaar weet vrijwel altijd wie de mol is, maar weet het pas de laatste paar afleveringen | De verliezer weet meestal niet wie de mol is en had net zo goed kop of munt kunnen gokken | De mol wordt eigenlijk alleen door de winnaar ontmaskerd | De prijzenpot voor WidM is gedaald | We kunnen geen relatie vinden tussen het percentage van de pot die wordt binnengehaald en het mate van verdenking op mol of winnaar | We kunnen op basis van de verdenkingen in de finale iets beter voorspellen wie de mol is (12 van de 18 seizoenen goed voorspeld) | Voor de toekomst kan het leuk zijn om de verdenkingen van het publiek via de mol-app te bekijken. Doen de tv kijkers het beter of wordt er maar wat gegokt en krijgen we eigenlijk te weinig echte hints? | . Welke vragen heb je zelf nog? Veel plezier met Wie is de Mol dit seizoen! . Hier kan je de jupyter notebook downloaden: https://github.com/jvanelteren/wie_is_de_mol . Mocht je data science leuk vinden kan ik je van harte aanraden om eens een gratis online Python programmeercursus te volgen! .",
            "url": "https://jvanelteren.github.io/blog/2019/01/12/WIDM.html",
            "relUrl": "/2019/01/12/WIDM.html",
            "date": " • Jan 12, 2019"
        }
        
    
  
    
        ,"post11": {
            "title": "Building a Crypto Trading Bot",
            "content": "What drives you when working on a project? For me motivation is made up of several components: . Curiosity: discover new insights about an interesting topic | Reaching a goal: have a sense of progressing to a goal by solving small obstacles | Learning: grow a skillset and be able to take on larger goals | Challenge &amp; Mastery: overcoming the nagging feeling if I’ll be also to tackle the project | . When I had an idea during the rise of bitcoin these elements where definitely there. But there was another big motivator... . I had made some money with the rise of bitcoin by buying it early and holding on to it. But what would be even better: a constant risk-free return without having to put much effort in. And that was exactly the idea that came to mind. Simple arbitrage: you open an account on multiple crypto exchanges and monitor the prices for different coins. When the prices are drifting apart you take up two positions: buying a coin at exchange A for a low price, and at the same time selling a coin short at exchange B for a high price. Then transferring the coin you’ve bought at exchange A to exchange B to neutralize the position and voila: profit. If I could have a program running on the background this would make me rich! It required a couple of functionalities to program: monitoring the prices though an API, taking up positions, neutralizing these positions and making sure to have enough crypto funds on the buying exchange. The spreads between the exchanged need to outweigh the transaction and transfer costs in order to be profitable. . I experienced how this sense of building a golden goose boosted my motivation to new highs. Sometimes I focus a lot on projects to make progress, but this was really next level 😊. After many hours of coding and learning to interact with crypto API&#39;s, I got everything to work automatically. But alas, the opportunities for risk-free arbitrage became very limited, as a result of the markets maturing. The spreads started to get smaller and smaller making my bot not profitable anymore. . Greed is at the core of many things wrong in this world, but in this case it provided me a very fun and valuable learning experience. .",
            "url": "https://jvanelteren.github.io/blog/2018/03/02/cryptobot.html",
            "relUrl": "/2018/03/02/cryptobot.html",
            "date": " • Mar 2, 2018"
        }
        
    
  
    
        ,"post12": {
            "title": "Finding a second hand car bargain",
            "content": "When doing the Udacity Machine Learning Engineer course some years ago I had to come up with a capstone project. Being in the market for a new car, I decided to see if I could predict the price of a second-hand car. This project followed a typical data science workflow: . Coming up with an idea This step if not always mentioned, but it is and extremely important step. If you don’t come up with an idea you cannot realize it! . | Data gathering I choose gaspedaal.nl as site and scraped about 350.000 cars from it. Scraping itself can be legally sketchy, but since this was an academic project and I didn’t overload the server I figured it would be ok. Also Gaspedaal.nl is itself a site that scrapes several car marketplaces. . | Data cleaning &amp; preprocessing This step makes sure the data will be of use for a model. It involves removing certain outliers, processing of categorical variables. We all know the garbage in, garbage out principle. . | Model selection The model should generate predictions, but which algorithm to choose. Trying out helps! Choosing some sensible options and pick the best performing one. When you execute a project in a corporate setting of course other deliberations are important such as maintainability, robustness and speed . | Model optimizing Many models have a set of knobs to turn, but what position to put them in for the best results. Again: trying out helps. I’m still looking for a nice Design of Experiments package to do this, but in this project I used the RandomGridSearch, which basically tries and sees what works. . | Model interpretation People often complain about machine learning being a black box, but when you’re not dealing with neural nets that statement is incorrect. Visualisation is the easiest step, but there are also packages that open up the black box, such as the shap package. . | . The model worked nicely and I was able to find a reasonably priced Toyota Prius with it. It has two weaknesses though: . The prices on the website are asking prices, not the final selling price. | If the model shows a car is ‘cheap’, it may be it has other problems (no maintenance? damage?). That’s why I did test the car at my own garage before making the purchase. | .",
            "url": "https://jvanelteren.github.io/blog/2017/06/29/cars.html",
            "relUrl": "/2017/06/29/cars.html",
            "date": " • Jun 29, 2017"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Visit my linkedin profile .",
          "url": "https://jvanelteren.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jvanelteren.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}