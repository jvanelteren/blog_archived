{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current preffered data science setup\n",
    "> And some tips on getting it to work on Google Cloud Platform\n",
    "\n",
    "- toc: false\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Jesse van Elteren\n",
    "- image: images/gcp.png\n",
    "- categories: []"
   ]
  },
  {
   "source": [
    "I’ve spend some time tinkering with getting a preferred data science stack up. In this post I’m detailing the choices made and could also help you get started on GCP. If you just want to start with programming, go to [Google Colab](https://colab.research.google.com/) and you're set to go."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![](datascience/stack.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The data science setup is now made up of:\n",
    "\n",
    "* All development in Python (installed via [Miniconda](https://docs.conda.io/en/latest/miniconda.html)), with [Pytorch](https://pytorch.org/) and [Fast.ai](https://www.fast.ai/) for deep learning\n",
    "* A personal computer with [Windows 10](https://www.microsoft.com/nl-nl/store/b/windows), [VSCode](https://code.visualstudio.com/) with [Jupyter notebooks](https://jupyter.org/) functionality\n",
    "* [Google Cloud Platform](https://cloud.google.com/) with a [Docker](https://www.docker.com/) container running [Linux Ubuntu](https://ubuntu.com/)\n",
    "* [Github](https://github.com/jvanelteren) for storing the codebase and a github action based blog running [fastpages](https://fastpages.fast.ai/)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For me this works best at the moment. Some remarks on tradeoffs.\n",
    "\n",
    "* Python vs other languages. Python is todays language of choice for data science. It's just so simple to express ideas in code. Also there are just so many packages available with useful functionality that the whole world is basically an import statement away. Maybe I’ll learn Julia, Kotlin or Swift once, but for now I’m set.\n",
    "\n",
    "* Pytorch vs TensorFlow: Pytorch is so much easier compared to Tensorflow. I remember doing an introduction on Tensorflow and I found it difficult to grasp.\n",
    "\n",
    "* Pytorch vs Fast.ai. Fast.ai is kind of the Keras of Pytorch. It has been a blessing and I do highly recommend it. The online course is great. Also you can get a deeplearning model running in no time. But it’s also an extra layer of abstraction to remember on top of trying to learn Pytorch. So right now I’m now mostly using with Pytorch and Fast.ai once in a while.\n",
    "\n",
    "* Windows vs Linux: OK for data science everyone says Linux is the go to, but I’m just so accustomed to Windows! I can definitely see the advantages of Linux and are slowly gravitating towards using a command line interface more. Windows made a big step with WSL2, so you can now run Linux from within Windows easily, so I did install Ubuntu locally. Maybe in the future I’ll switch fully to Linux, but for now this is working fine.\n",
    "\n",
    "* VSCode vs Jupyter Notebooks. In my opinion the setup of running notebooks within VSCode combines the advantages of a fully fledged IDE with the agile development that notebooks are known for.\n",
    "\n",
    "* Having an own computer vs doing everything in the cloud. Working in the cloud always has a startup of a couple of minutes. My time is limited, so I do prefer to open VSCode and start coding right away. When I need more compute I use the cloud.\n",
    "\n",
    "* GCP vs other cloud platforms. This decision was taken based on the $300 free credit you get with GCP.\n",
    "\n",
    "* Github: Initially I had all the code on my local computer and I used Git for version control. Now that I sometimes iterate between working locally and in the cloud, I store the main branch on Github and push/pull from whichever environment I’m working on.\n",
    "\n",
    "* Fastpages: First I started on Medium, but fastpages is a live saver for publishing from notebooks. It makes it actually fun to blog, instead of a chore duplicating your work in a blog article\n",
    "\n",
    "* Docker: For reproducibility, Docker is king. For cloud computing I think it’s the best way. You just make a Dockerfile and know what you will get. Also it can make the steps to deployment easier.\n",
    "\n",
    "* App deployment: Don’t know what the best is yet. Have tried Render, and could get a webserver it to work with GCP as well. You can even deploy on Binder with a notebook. Guess this one depends on the use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remainer of the post is dedicated to helping you out with setting up GCP with Docker. Some things you need:\n",
    "\n",
    "* The CLI command from Windows to get a VM running\n",
    "* A startup script to make sure the VM runs the container\n",
    "* A Dockerfile to build a docker image from\n",
    "\n",
    "Let's start with the CLI command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcloud beta compute instances create gpu `\n",
    "--zone=us-central1-c `\n",
    "--machine-type=n1-standard-8 `\n",
    "--subnet=default `\n",
    "--service-account=YOURSERVICEACCOUNT-compute@developer.gserviceaccount.com `\n",
    "--image-family=common-cu110 `\n",
    "--image-project=deeplearning-platform-release `\n",
    "--boot-disk-size=50GB `\n",
    "--scopes=https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/devstorage.full_control `\n",
    "--accelerator=type=nvidia-tesla-k80,count=1 `\n",
    "--metadata=install-nvidia-driver=True `\n",
    "--maintenance-policy=TERMINATE `\n",
    "--metadata-from-file startup-script=startup-gpu.sh `\n",
    "--preemptible"
   ]
  },
  {
   "source": [
    "You can create a GCP VM from the command line interface (CLI) or through the browser based console. Play around with the console to get an idea. Then, on the bottom click gcloud command to see the CLI command to copy in your terminal\n",
    "\n",
    "This command uses ` at end of line since it's run from Windows Powershell. If you use Linux, use backslash \\\n",
    "\n",
    "Don't use Container Optimizer OS, as of november 2020 they dont install nvidia container runtime, meaning it's difficult to make use of the GPU inside the container. An approach that works is to use a data science image like common-cu110 as I've used here. \n",
    "\n",
    "The K80 is the cheapest GPU, good for experimenting.\n",
    "\n",
    "Also, use --preemtible. You're VM may be stopped unexpectedly, but it's about 66% cheaper!\n",
    "\n",
    "Next up is the startup script..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "# first some waiting until gpu drivers are truly installed\n",
    "while ! [[ -x \"$(command -v nvidia-smi)\" ]];\n",
    "do\n",
    "  echo \"sleep to check\"\n",
    "  sleep 5s\n",
    "done\n",
    "echo \"nvidia-smi is installed\"\n",
    "\n",
    "while [[ $(command nvidia-smi| cut -c1-10) == \"NVIDIA-SMI\"* ]];\n",
    "do\n",
    "  echo \"$(command nvidia-smi)\"\n",
    "  echo \"sleeping to check\"\n",
    "  sleep 5s\n",
    "done\n",
    "echo \"$(command nvidia-smi)\"\n",
    "echo \"nvidia-smi drivers are up\"\n",
    "\n",
    "# if you have a persistent disk you can use this to automatically mount it, otherwise remove it\n",
    "if [ ! -d \"/mnt/disks/storage\" ] \n",
    "then\n",
    "  sudo mkdir -p /mnt/disks/storage\n",
    "  sudo mount -o discard,defaults /dev/sdb /mnt/disks/storage\n",
    "  sudo chmod a+w /mnt/disks/storage\n",
    "  sudo cp /etc/fstab /etc/fstab.backup\n",
    "  sudo blkid /dev/sdb\n",
    "  echo UUID=`sudo blkid -s UUID -o value /dev/sdb` /mnt/disks/storage ext4 discard,defaults,nofail 0 2 | sudo tee -a /etc/fstab\n",
    "  echo \"mounting complete \"\n",
    "else\n",
    "  echo \"not first startup\"\n",
    "fi\n",
    "\n",
    "# startup your Docker container, with port 6006 mapped to Docker for Tensorboard\n",
    "gcloud auth configure-docker\n",
    "docker run -d -p 0.0.0.0:6006:6006 --gpus all --ipc=\"host\" -v /mnt/disks/storage:/ds gcr.io/delta-deck-285906/dockerfile  \n",
    "echo 'Docker run with GPUs'"
   ]
  },
  {
   "source": [
    "The first part of the startup script is mainly to wait until the gpu drivers are properly installed. Otherwise, docker run --gpus all will throw an error. Additionally, I like to use a persistent disk. To avoid the hassle of having to mount it every time I startup a new VM, this script does the work for you. Finally the most important is the Docker run instruction. It opens your container with GPU support. The first time you start up your VM it will take some minutes, but afterwards it's almost immediate.\n",
    "\n",
    "After this I like to connect to the running container with Vscode Remote-Container Attach to running container command. Checkout the Vscode docs for how to set this up. Basically you need to put the external ip of the VM into your SSH config file and add a line to your settings.json"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings.json\n",
    "\"docker.host\": \"ssh://YOURUSER@xxx.xxx.xxx.xxx\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Host xxx.xxx.xxx.xxx\n",
    "  HostName xxx.xxx.xxx.xxx.xxx\n",
    "  IdentityFile localpath/to/publicsshkey\n",
    "  User YOURUSER\n",
    "  StrictHostKeyChecking no"
   ]
  },
  {
   "source": [
    "One final file to share: the Dockerfile which you can use to build your Docker image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM nvidia/cuda:10.2-runtime-ubuntu18.04\n",
    "\n",
    "##Set environment variables\n",
    "ENV LANG=C.UTF-8 LC_ALL=C.UTF-8\n",
    "\n",
    "RUN apt-get update --fix-missing && apt-get install -y wget byobu\\\n",
    "    curl \\\n",
    "    git-core \\\n",
    "    python3-virtualenv \\\n",
    "    unzip \\\n",
    "    && \\\n",
    "    apt-get clean && \\\n",
    "    rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-py38_4.8.3-Linux-x86_64.sh -O ~/miniconda.sh && \\\n",
    "    /bin/bash ~/miniconda.sh -b -p /opt/conda && \\\n",
    "    rm ~/miniconda.sh && \\\n",
    "    ln -s /opt/conda/etc/profile.d/conda.sh /etc/profile.d/conda.sh && \\\n",
    "    echo \". /opt/conda/etc/profile.d/conda.sh\" >> ~/.bashrc && \\\n",
    "    echo \"conda activate base\" >> ~/.bashrc\n",
    "    \n",
    "ENV PATH /opt/conda/bin:$PATH\n",
    "\n",
    "RUN pip --no-cache-dir install --upgrade \\\n",
    "        altair \\\n",
    "        ipykernel \\\n",
    "        kaggle \\\n",
    "        fastbook \\\n",
    "        tensorboard \\\n",
    "        diskcache \\\n",
    "        && \\\n",
    "    conda install -c fastai -c pytorch fastai && \\\n",
    "    pip uninstall -y pillow && \\\n",
    "    pip install pillow-simd --upgrade && \\\n",
    "    mkdir -p ds/.kaggle && \\\n",
    "    git clone https://github.com/fastai/fastbook.git /ds/fastbook\n",
    "\n",
    "# Open Ports for Jupyter\n",
    "# EXPOSE 7745\n",
    "\n",
    "#Setup File System\n",
    "ENV HOME=/ds\n",
    "ENV SHELL=/bin/bash\n",
    "ENV KAGGLE_CONFIG_DIR=/ds/.kaggle\n",
    "VOLUME /ds\n",
    "WORKDIR /ds\n",
    "\n",
    "# Make sure the container stays open\n",
    "CMD tail -f /dev/null"
   ]
  },
  {
   "source": [
    "The [Docker tutorial by Hamel Husain](https://towardsdatascience.com/how-docker-can-help-you-become-a-more-effective-data-scientist-7fc048ef91d5) has helped me greatly, especially the advice to use someone elses dockerfile and start making it your own by gradually adapting. The above dockerfile is based upon his actually.\n",
    "\n",
    "That's it, hope it has helped you!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.3 64-bit",
   "display_name": "Python 3.7.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}