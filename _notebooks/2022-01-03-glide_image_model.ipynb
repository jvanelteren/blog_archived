{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing around with Glide image model\n",
    "> Text to image now almost tackled?\n",
    "\n",
    "- toc: false\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Jesse van Elteren\n",
    "- image: images/glideimg.png\n",
    "- categories: []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[THIS POST IS WORK IN PROGRESS]\n",
    "\n",
    "You probably know that a computer can come up with a description of an image. For example an image of a dog playing with your kids in a garden may be converted into 'dog and children in garden'.\n",
    "\n",
    "But did you know the other way around is now also possible? You come up with your textual description and the computer renders a **new** image. As in completely new, it's not like a google search which searches existing images. Let's check it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI has been one of the premier organisations publishing spectacular results in the past years. They mainly take huge datasets of texts and images and train their models on it. They released [a paper](https://arxiv.org/pdf/2112.10741.pdf) on their GLIDE image model, trained on several hundred million images. It outperforms their previous already amazing DALL-E model in terms of photorealism.\n",
    "\n",
    "They also open-sourced [a slimmed down version of their model](https://github.com/openai/glide-text2im). I played around with it by coming up with some text prompts and let the model generate 10 images for each promt. I selected a range of prompts that gives you an insights to the power, but also the limitations of the released model. Below the results, where I repeat the prompt above the images which makes scrolling on mobile easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from pathlib import Path\n",
    "import imageio as iio\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "def longer(name):\n",
    "    total = 350\n",
    "    postfix = '                                    '\n",
    "    l = len(name) + len(postfix)\n",
    "    return postfix.join([name for _ in range(total//l)])\n",
    "    \n",
    "p = Path('summary')\n",
    "filenames = [file.name for file in p.iterdir()]\n",
    "filenames = [longer(filenames[i].replace('_1.png', '')) for i in range(0,len(filenames),10)]\n",
    "\n",
    "images = list()\n",
    "for file in p.iterdir():\n",
    "    im = iio.imread(file)\n",
    "    images.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "font = ImageFont.truetype(r'C:\\Windows\\Fonts\\arial.ttf', 20) \n",
    "allimgs = []\n",
    "for i in range(0,len(images),10):\n",
    "    # concat every 10 images\n",
    "    imgs = np.hstack(images[i:i+10])\n",
    "    # add a white box above\n",
    "    white = np.full((30,2560,3), 255).astype('uint8')\n",
    "    # convert to image\n",
    "    text_and_imgs = Image.fromarray(np.concatenate([white, imgs]), 'RGB')\n",
    "    # add text\n",
    "    draw = ImageDraw.Draw(text_and_imgs)\n",
    "    draw.text((3, 5),filenames[i//10], fill='blue', font=font)\n",
    "    allimgs.append(text_and_imgs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_input\n",
    "# concat all the text_img files\n",
    "def get_concat_v(im1, im2):\n",
    "    dst = Image.new('RGB', (im1.width, im1.height + im2.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (0, im1.height))\n",
    "    return dst\n",
    "full_img = reduce(get_concat_v, allimgs)\n",
    "full_img.save('glide/summary.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](glide/summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you also see this:\n",
    "* The more complex prompts sometimes are only partially fulfilled. For example: a painting of a cat playing checkers does generate paintings of cats, but not playing checkers\n",
    "* The representation sometimes is off, with certain animals you can clearly see it's not correct. \n",
    "* The model can be quite wide in it's approch. When you think of a map of a city, you probably have 1 type of map in your head. The model generates all sorts of types of maps, all believable\n",
    "\n",
    "Some I also had a culinary adventure. I tried out 'spagetthi on a plate' but got stuff that honestly looked... awful... Turned out I misspelled it (should be spaghetti) and the corrected dish looked much better. Then I tried to make it delicious and worked out pretty nicely!\n",
    "\n",
    "![](glide/spag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their full model is larger and also is trained on images of people. See these impressive examples from the paper:\n",
    "\n",
    "![](glide/paper.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are even more examples in [the paper](https://arxiv.org/pdf/2112.10741), check it out! And in case you can't get enough, I've got more results here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This clearly is a disruption to the stock photo business and the next step forward.\n",
    "\n",
    "At this point AI can generate believeable news articles including images that are completely false. Still though, many experts feel that we are currently a long way from Artifical General Intelligence and the current deep learning architectures may not get us to AGI. But it doesn't make these more narrow applications less impressive. Hope you enjoyed it!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b89b5cfaba6639976dc87ff2fec6d58faec662063367e2c229c520fe71072417"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
